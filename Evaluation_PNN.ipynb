{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db15e4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import evaluation_vectorization as ev\n",
    "import random\n",
    "import config\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), 'Aging_Model'))\n",
    "import FigureConfig as FC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee1997d-b1eb-473b-9ade-ebcc8cc39364",
   "metadata": {},
   "source": [
    "# Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "736bb529-3d35-484b-b44c-6810ec362bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cuda:0')\n",
    "device = 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6997e0-dc56-4a5d-8d5e-fae1243e9f77",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63ddb1ed-59cf-4fe1-ae3f-48be2a3e908d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pendigits'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if config.current_dataset is not None:\n",
    "    ds = config.datasets[config.current_dataset]\n",
    "else:\n",
    "    ds = config.datasets[0]\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee64d8d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10992, 16]), torch.Size([10992]), 10992, 16, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath = os.path.join(config.path, f'Dataset_{ds}.p')\n",
    "with open(datapath, 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "X = dataset['X'].float()\n",
    "y = dataset['y']\n",
    "E, N_features, N_class = X.shape[0], X.shape[1], torch.max(\n",
    "    torch.unique(y)).item()+1\n",
    "X.shape, y.shape, E, N_features, N_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddc925e-6683-4136-b459-29eda4e3544c",
   "metadata": {},
   "source": [
    "## Pseudo-electrical Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd09c7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(1.))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalization\n",
    "X = X - torch.min(X, axis=0)[0]\n",
    "X = X / torch.max(X, axis=0)[0]\n",
    "torch.min(X), torch.max(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bad80729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6595, 2048, 2048)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# generate tensordataset\n",
    "dataset = TensorDataset(X.to(device), y.to(device))\n",
    "\n",
    "# split\n",
    "train_rate = 0.6\n",
    "valid_rate = 0.2\n",
    "test_rate = 0.2\n",
    "E_train = min(8096, int(E*train_rate))\n",
    "E_valid = min(2048, int(E*valid_rate))\n",
    "E_test = min(2048, int(E*test_rate))\n",
    "\n",
    "random.seed(config.data_split_seed);\n",
    "np.random.seed(config.data_split_seed);\n",
    "torch.manual_seed(config.data_split_seed);\n",
    "\n",
    "train_data, rest_data = random_split(dataset, [E_train, E-E_train])\n",
    "valid_data, rest_data = random_split(rest_data, [E_valid, E-E_train-E_valid])\n",
    "test_data, rest_data = random_split(rest_data, [E_test, E-E_train-E_valid-E_test])\n",
    "\n",
    "len(train_data), len(valid_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbe0bdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch\n",
    "train_loader = DataLoader(train_data, batch_size=len(train_data))\n",
    "valid_loader = DataLoader(valid_data, batch_size=len(valid_data))\n",
    "test_loader = DataLoader(test_data, batch_size=len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d84ed3",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9299f5-ed31-46e2-991f-e69004f47608",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "391d962c-56b7-4e21-9b95-06a234564425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46db00bd2124e0699c9c43aec042109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m0\u001b[39m);\n\u001b[1;32m     11\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m0\u001b[39m);\n\u001b[0;32m---> 13\u001b[0m mean_acc_PNN, std_acc_PNN, mean_maa_PNN, std_maa_PNN, loss \u001b[38;5;241m=\u001b[39m \u001b[43mev\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEvaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPNN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mM_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mM_test\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mK_test\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m accs\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(mean_acc_PNN))\n\u001b[1;32m     15\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss)\n",
      "File \u001b[0;32m/pfs/data5/home/kit/tm/px3192/Aging-aware-training/evaluation_vectorization.py:90\u001b[0m, in \u001b[0;36mEvaluation\u001b[0;34m(nn, test_loader, M_test, M_max, K_test, device, T)\u001b[0m\n\u001b[1;32m     88\u001b[0m xv_test \u001b[38;5;241m=\u001b[39m x_test\u001b[38;5;241m.\u001b[39mrepeat(M_max, K_test, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# inference\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxv_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# vectorization of testing labels\u001b[39;00m\n\u001b[1;32m     92\u001b[0m yv_test \u001b[38;5;241m=\u001b[39m y_test\u001b[38;5;241m.\u001b[39mrepeat(M_max, K_test, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/pfs/data5/home/kit/tm/px3192/Aging-aware-training/pNN_aging_aware_vectorization.py:143\u001b[0m, in \u001b[0;36mPNNLayer.forward\u001b[0;34m(self, a_previous)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, a_previous):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m    forward propagation: MAC and activation\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m    :param a: input of the layer\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03m    :return: output of the layer\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m     z_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmac\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_previous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m     a_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivate(z_new)\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m a_new\n",
      "File \u001b[0;32m/pfs/data5/home/kit/tm/px3192/Aging-aware-training/pNN_aging_aware_vectorization.py:101\u001b[0m, in \u001b[0;36mPNNLayer.mac\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m     97\u001b[0m m, n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtheta\u001b[38;5;241m.\u001b[39mshape  \u001b[38;5;66;03m# number of output and input neurons\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# enlarge for parameter b and d\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# a changes from [M, K, E, n_in] to [M, K, E, n_in+2]\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxpu\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxpu\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# calculate the negative a, i.e. inv(a)\u001b[39;00m\n\u001b[1;32m    105\u001b[0m InvX \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minv(a)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "losses = []\n",
    "\n",
    "for seed in range(10):\n",
    "    with open(f'./result/{ds}_PNN_{seed}.p', 'rb') as f:\n",
    "        PNN = pickle.load(f)\n",
    "    PNN.to(device)\n",
    "    \n",
    "    random.seed(0);\n",
    "    np.random.seed(0);\n",
    "    torch.manual_seed(0);\n",
    "    \n",
    "    mean_acc_PNN, std_acc_PNN, mean_maa_PNN, std_maa_PNN, loss = ev.Evaluation(PNN, valid_loader, config.M_test, int(config.M_test/10), config.K_test*10, device, T=10)\n",
    "    accs.append(np.mean(mean_acc_PNN))\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c40172-f714-4e1f-922f-4fcfc86f1cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seed = np.argmin(losses)\n",
    "best_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fea1316-6d8e-485c-98d6-821dfbcc10a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses[best_seed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0fdf2e-359a-4590-acbd-2eabca6c90f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./result/{ds}_PNN_{best_seed}.p', 'rb') as f:\n",
    "    PNN = pickle.load(f)\n",
    "PNN.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab18cd0-bbd8-4fbb-b90e-81fd90a52eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc_PNN, std_acc_PNN, mean_maa_PNN, std_maa_PNN, loss = ev.Evaluation(PNN, test_loader, config.M_test, int(config.M_test/10), config.K_test*10, device, T=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3040bd-1712-46e6-981b-ada6c398baaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9540fac0-790a-45dd-acd4-8cb003c81ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f'./result/figures/{ds}_PNN_ACC_{best_seed}_{int(np.mean(mean_acc_PNN)*1000)}.txt', np.vstack((mean_acc_PNN, std_acc_PNN)))\n",
    "np.savetxt(f'./result/figures/{ds}_PNN_MAA_{best_seed}_{int(np.mean(mean_maa_PNN)*1000)}.txt', np.vstack((mean_maa_PNN, std_maa_PNN)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dc9c70-569e-410c-b4af-5758e6b82384",
   "metadata": {},
   "outputs": [],
   "source": [
    "if losses[best_seed]==0:\n",
    "    if loss==0:\n",
    "        overfitting = 1\n",
    "    else:\n",
    "        overfitting = 10000\n",
    "else:\n",
    "    overfitting = loss/losses[best_seed]\n",
    "np.savetxt(f'./result/figures/{ds}_PNN_loss.txt', np.array([losses[best_seed], loss, overfitting]), fmt='%.10f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0cdb9fb-1ca3-4671-a2b3-4607d8fc68e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = dict()\n",
    "test['a'] = 1\n",
    "test['b'] = 2\n",
    "with open(f'mytestdict.p', 'wb') as f:\n",
    "    pickle.dump(test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0520f0d1-e1d9-49a3-9b80-d1deaef894fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'mytestdict.p', 'rb') as f:\n",
    "    tryread = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14015a2-e71b-4d55-a394-5f099c235cab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "machinelearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
