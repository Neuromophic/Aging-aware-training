{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0f1319a",
   "metadata": {},
   "source": [
    "# Aging Aware with Model Variation\n",
    "Previously, we optimize the following functional:\n",
    "$$ \\min_\\theta \\, \\int_{t=0}^{1} \\; L(\\theta(t)) \\, {\\rm d}t. $$\n",
    "The optimum is for a specific aging model $\\omega$, i.e., we minimized the \n",
    "$$ \\min_\\theta \\, \\int_{t=0}^{1} \\; L(\\theta(t,\\omega)) \\, {\\rm d}t. $$\n",
    "However, we dont know how will the resistance decay, i.e., we should also minimize the loss function w.r.t. aging models with different parameters. That means we need to optimized\n",
    "$$ \\min_\\theta \\, \\int_{\\omega}\\int_{t=0}^{1} \\; L(\\theta(t,\\omega)) \\, {\\rm d}t\\, p(\\omega){\\rm d}\\omega. $$\n",
    "The Mento Carlo Approximation is then\n",
    "$$\n",
    "\\min_{\\theta_{\\rm init}} \\frac{1}{\\Omega}\\frac{1}{K}\\sum_{\\omega\\in\\mathfrak{M}}\\sum_{k\\in \\mathfrak{K} } L \\left(\\theta[k, \\omega]\\right),\n",
    "$$\n",
    "where $\\mathfrak{M}$ is the set of $\\Omega$ elements following the distribution $p(\\omega)$. $p(\\omega)$ is the distributions of parameters of the aging model. We have already obtained these distributions as we modeled the aging decay.\n",
    "\n",
    "That means we should optimize this problem by\n",
    "$$\n",
    "\\begin{align}\n",
    "\\theta_{\\rm init}&:=\\theta_{\\rm init} - \\alpha\\cdot\\nabla_{\\theta_{\\rm init}}\\left(\\frac{1}{\\Omega}\\frac{1}{K}\\sum_{\\omega\\in\\mathfrak{M}}\\sum_{k\\in \\mathfrak{K} } L \\left(\\theta[k, \\omega]\\right)\\right)\\\\\n",
    "&=\\theta_{\\rm init} - \\frac{\\alpha}{\\Omega K}\\cdot\\nabla_{\\theta_{\\rm init}}\\left(\\sum_{\\omega\\in\\mathfrak{M}}\\sum_{k\\in \\mathfrak{K} } L \\left(\\theta[k, \\omega]\\right)\\right)\\\\\n",
    "&=\\theta_{\\rm init} - \\frac{\\alpha}{\\Omega K}\\left(\\sum_{\\omega\\in\\mathfrak{M}}\\sum_{k\\in \\mathfrak{K} }\\nabla_{\\theta_{\\rm init}} L \\left(\\theta[k, \\omega]\\right)\\right)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab183f8",
   "metadata": {},
   "source": [
    "# Get aging model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bc40b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import pickle\n",
    "import pNN_aging_aware as pnn\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import training\n",
    "import PNN_Setting as ps\n",
    "sys.path.append(os.path.join(os.getcwd(), 'Aging_Model'))\n",
    "\n",
    "with open(os.path.join(os.getcwd(), 'Aging_Model', 'exp_aging_model.p'), 'rb') as f:\n",
    "    age_generator = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15519567",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9b925b",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd3f8c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10992, 16]), torch.Size([10992]), 10992, 16, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath = os.path.join(os.getcwd(), 'Datasets', 'PMLC',\n",
    "                        'data_processed', 'Dataset_Pendigits.p')\n",
    "with open(datapath, 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "X = dataset['X'].float()\n",
    "y = dataset['y']\n",
    "M, N_features, N_class = X.shape[0], X.shape[1], torch.max(\n",
    "    torch.unique(y)).item()+1\n",
    "X.shape, y.shape, M, N_features, N_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35adbc19",
   "metadata": {},
   "source": [
    "## data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea0969cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(1.))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalization\n",
    "X = X / (torch.max(X, axis=0)[0] - torch.min(X, axis=0)[0])\n",
    "X = X - torch.min(X, axis=0)[0]\n",
    "torch.min(X), torch.max(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d04d54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4700, 1.0000, 0.2700, 0.8100, 0.5700, 0.3700, 0.2600, 0.0000, 0.0000],\n",
       "        [0.0000, 0.8900, 0.2700, 1.0000, 0.4200, 0.7500, 0.2900, 0.4500, 0.1500],\n",
       "        [0.0000, 0.5700, 0.3100, 0.6800, 0.7200, 0.9000, 1.0000, 1.0000, 0.7600],\n",
       "        [0.0000, 1.0000, 0.0700, 0.9200, 0.0500, 0.6800, 0.1900, 0.4500, 0.8600],\n",
       "        [0.0000, 0.6700, 0.4900, 0.8300, 1.0000, 1.0000, 0.8100, 0.8000, 0.6000],\n",
       "        [1.0000, 1.0000, 0.8800, 0.9900, 0.4900, 0.7400, 0.1700, 0.4700, 0.0000],\n",
       "        [0.0000, 1.0000, 0.0300, 0.7200, 0.2600, 0.3500, 0.8500, 0.3500, 1.0000],\n",
       "        [0.0000, 0.3900, 0.0200, 0.6200, 0.1100, 0.0500, 0.6300, 0.0000, 1.0000],\n",
       "        [0.1300, 0.8900, 0.1200, 0.5000, 0.7200, 0.3800, 0.5600, 0.0000, 0.0400],\n",
       "        [0.5700, 1.0000, 0.2200, 0.7200, 0.0000, 0.3100, 0.2500, 0.0000, 0.7500]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10, :9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d30ecfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6595, 2198, 2199)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# generate tensordataset\n",
    "dataset = TensorDataset(X, y)\n",
    "\n",
    "# split\n",
    "train_rate = 0.6\n",
    "test_rate = 0.2\n",
    "M_train = int(M*train_rate)\n",
    "M_test = int(M*test_rate)\n",
    "train_data, rest_data = random_split(dataset, [M_train, M-M_train], generator=torch.Generator().manual_seed(19950102))\n",
    "test_data, valid_data = random_split(rest_data, [M_test, M-M_train-M_test], generator=torch.Generator().manual_seed(19950102))\n",
    "len(train_data), len(test_data), len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f8988b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch\n",
    "train_loader = DataLoader(train_data, batch_size=len(train_data))\n",
    "test_loader = DataLoader(test_data, batch_size=len(test_data))\n",
    "valid_loader = DataLoader(valid_data, batch_size=len(valid_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0f57e2",
   "metadata": {},
   "source": [
    "# Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "608550a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Hidden = 16\n",
    "m = 0.3\n",
    "T = 0.1\n",
    "K = 5  # number of time sampling\n",
    "M = 40  # number of model sampling\n",
    "K_test = 5\n",
    "M_test = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b3bda2",
   "metadata": {},
   "source": [
    "# Normal NN\n",
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4874b4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=16, out_features=10, bias=True)\n",
       "  (3): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN = torch.nn.Sequential(torch.nn.Linear(N_features, N_Hidden), torch.nn.Tanh(),\n",
    "                         torch.nn.Linear(N_Hidden, N_class), torch.nn.Tanh())\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "\n",
    "NN.apply(weights_init)\n",
    "\n",
    "optimizer_NN = torch.optim.Adam(NN.parameters(), lr=0.01)\n",
    "celoss = torch.nn.CrossEntropyLoss()\n",
    "NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f244a366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d77da4ceb843b7918ec20bcefd1e4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch:     0 | Accuracy: 0.09782 | Loss: 2.433520555 |\n",
      "| Epoch:   100 | Accuracy: 0.76661 | Loss: 1.177825809 |\n",
      "| Epoch:   200 | Accuracy: 0.85851 | Loss: 1.015358686 |\n",
      "| Epoch:   300 | Accuracy: 0.87352 | Loss: 0.953737378 |\n",
      "| Epoch:   400 | Accuracy: 0.88171 | Loss: 0.922604620 |\n",
      "| Epoch:   500 | Accuracy: 0.89263 | Loss: 0.905694723 |\n",
      "| Epoch:   600 | Accuracy: 0.89718 | Loss: 0.893669248 |\n",
      "| Epoch:   700 | Accuracy: 0.90628 | Loss: 0.884059668 |\n",
      "| Epoch:   800 | Accuracy: 0.91174 | Loss: 0.876420736 |\n",
      "| Epoch:   900 | Accuracy: 0.91583 | Loss: 0.871099234 |\n",
      "| Epoch:  1000 | Accuracy: 0.91856 | Loss: 0.867481709 |\n",
      "| Epoch:  1100 | Accuracy: 0.92175 | Loss: 0.864668489 |\n",
      "| Epoch:  1200 | Accuracy: 0.92175 | Loss: 0.862232566 |\n",
      "| Epoch:  1300 | Accuracy: 0.92584 | Loss: 0.860176206 |\n",
      "| Epoch:  1400 | Accuracy: 0.93267 | Loss: 0.858444810 |\n",
      "| Epoch:  1500 | Accuracy: 0.94177 | Loss: 0.856602967 |\n",
      "| Epoch:  1600 | Accuracy: 0.97361 | Loss: 0.850466549 |\n",
      "| Epoch:  1700 | Accuracy: 0.98044 | Loss: 0.837755680 |\n",
      "| Epoch:  1800 | Accuracy: 0.98089 | Loss: 0.836298406 |\n",
      "| Epoch:  1900 | Accuracy: 0.98226 | Loss: 0.835092366 |\n",
      "| Epoch:  2000 | Accuracy: 0.98317 | Loss: 0.834028721 |\n",
      "| Epoch:  2100 | Accuracy: 0.98317 | Loss: 0.833054721 |\n",
      "| Epoch:  2200 | Accuracy: 0.98408 | Loss: 0.832149088 |\n",
      "| Epoch:  2300 | Accuracy: 0.98408 | Loss: 0.831332922 |\n",
      "| Epoch:  2400 | Accuracy: 0.98408 | Loss: 0.830601394 |\n",
      "| Epoch:  2500 | Accuracy: 0.98362 | Loss: 0.829982936 |\n",
      "| Epoch:  2600 | Accuracy: 0.98362 | Loss: 0.829439223 |\n",
      "| Epoch:  2700 | Accuracy: 0.98362 | Loss: 0.828974903 |\n",
      "| Epoch:  2800 | Accuracy: 0.98408 | Loss: 0.828548789 |\n",
      "| Epoch:  2900 | Accuracy: 0.98408 | Loss: 0.828218877 |\n",
      "| Epoch:  3000 | Accuracy: 0.98362 | Loss: 0.828072309 |\n",
      "| Epoch:  3100 | Accuracy: 0.98271 | Loss: 0.827967584 |\n",
      "| Epoch:  3200 | Accuracy: 0.98226 | Loss: 0.827992439 |\n",
      "| Epoch:  3300 | Accuracy: 0.98226 | Loss: 0.828067541 |\n",
      "| Epoch:  3400 | Accuracy: 0.98226 | Loss: 0.827796876 |\n",
      "| Epoch:  3500 | Accuracy: 0.98226 | Loss: 0.827719033 |\n",
      "| Epoch:  3600 | Accuracy: 0.98226 | Loss: 0.827794909 |\n",
      "| Epoch:  3700 | Accuracy: 0.98271 | Loss: 0.827743709 |\n",
      "| Epoch:  3800 | Accuracy: 0.98271 | Loss: 0.827799082 |\n",
      "| Epoch:  3900 | Accuracy: 0.98317 | Loss: 0.827997386 |\n",
      "| Epoch:  4000 | Accuracy: 0.98362 | Loss: 0.828149199 |\n",
      "| Epoch:  4100 | Accuracy: 0.98317 | Loss: 0.828049541 |\n",
      "| Epoch:  4200 | Accuracy: 0.98362 | Loss: 0.827974856 |\n",
      "| Epoch:  4300 | Accuracy: 0.98362 | Loss: 0.827909410 |\n",
      "| Epoch:  4400 | Accuracy: 0.98362 | Loss: 0.827962458 |\n",
      "| Epoch:  4500 | Accuracy: 0.98362 | Loss: 0.827937245 |\n",
      "| Epoch:  4600 | Accuracy: 0.98362 | Loss: 0.827944279 |\n",
      "| Epoch:  4700 | Accuracy: 0.98408 | Loss: 0.827993929 |\n",
      "| Epoch:  4800 | Accuracy: 0.98408 | Loss: 0.828046381 |\n",
      "| Epoch:  4900 | Accuracy: 0.98453 | Loss: 0.828082621 |\n",
      "| Epoch:  5000 | Accuracy: 0.98453 | Loss: 0.828089178 |\n",
      "| Epoch:  5100 | Accuracy: 0.98499 | Loss: 0.828076422 |\n",
      "| Epoch:  5200 | Accuracy: 0.98499 | Loss: 0.828093469 |\n",
      "| Epoch:  5300 | Accuracy: 0.98499 | Loss: 0.828137994 |\n",
      "| Epoch:  5400 | Accuracy: 0.98499 | Loss: 0.828182995 |\n",
      "| Epoch:  5500 | Accuracy: 0.98499 | Loss: 0.828214407 |\n",
      "| Epoch:  5600 | Accuracy: 0.98499 | Loss: 0.828227103 |\n",
      "| Epoch:  5700 | Accuracy: 0.98499 | Loss: 0.828220010 |\n",
      "| Epoch:  5800 | Accuracy: 0.98453 | Loss: 0.828194082 |\n",
      "| Epoch:  5900 | Accuracy: 0.98453 | Loss: 0.828151345 |\n",
      "| Epoch:  6000 | Accuracy: 0.98499 | Loss: 0.828095376 |\n",
      "| Epoch:  6100 | Accuracy: 0.98453 | Loss: 0.828031600 |\n",
      "| Epoch:  6200 | Accuracy: 0.98499 | Loss: 0.827966630 |\n",
      "| Epoch:  6300 | Accuracy: 0.98499 | Loss: 0.827915430 |\n",
      "| Epoch:  6400 | Accuracy: 0.98544 | Loss: 0.827896953 |\n",
      "| Epoch:  6500 | Accuracy: 0.98544 | Loss: 0.827834964 |\n",
      "| Epoch:  6600 | Accuracy: 0.98544 | Loss: 0.827819884 |\n",
      "| Epoch:  6700 | Accuracy: 0.98544 | Loss: 0.827825487 |\n",
      "| Epoch:  6800 | Accuracy: 0.98499 | Loss: 0.827845454 |\n",
      "| Epoch:  6900 | Accuracy: 0.98499 | Loss: 0.827877283 |\n",
      "| Epoch:  7000 | Accuracy: 0.98499 | Loss: 0.827918172 |\n",
      "| Epoch:  7100 | Accuracy: 0.98453 | Loss: 0.827963710 |\n",
      "| Epoch:  7200 | Accuracy: 0.98499 | Loss: 0.828001618 |\n",
      "| Epoch:  7300 | Accuracy: 0.98499 | Loss: 0.827967286 |\n",
      "| Epoch:  7400 | Accuracy: 0.98499 | Loss: 0.827726245 |\n",
      "| Epoch:  7500 | Accuracy: 0.98499 | Loss: 0.827818274 |\n",
      "| Epoch:  7600 | Accuracy: 0.98544 | Loss: 0.828159094 |\n",
      "| Epoch:  7700 | Accuracy: 0.98590 | Loss: 0.828716993 |\n",
      "| Epoch:  7800 | Accuracy: 0.98499 | Loss: 0.829250932 |\n",
      "| Epoch:  7900 | Accuracy: 0.98499 | Loss: 0.829277158 |\n",
      "| Epoch:  8000 | Accuracy: 0.98499 | Loss: 0.829318583 |\n",
      "| Epoch:  8100 | Accuracy: 0.98499 | Loss: 0.829365790 |\n",
      "| Epoch:  8200 | Accuracy: 0.98499 | Loss: 0.829403520 |\n",
      "| Epoch:  8300 | Accuracy: 0.98499 | Loss: 0.829432189 |\n",
      "| Epoch:  8400 | Accuracy: 0.98499 | Loss: 0.829451025 |\n",
      "| Epoch:  8500 | Accuracy: 0.98499 | Loss: 0.829460621 |\n",
      "| Epoch:  8600 | Accuracy: 0.98499 | Loss: 0.829462469 |\n",
      "| Epoch:  8700 | Accuracy: 0.98453 | Loss: 0.829458535 |\n",
      "| Epoch:  8800 | Accuracy: 0.98453 | Loss: 0.829451621 |\n",
      "| Epoch:  8900 | Accuracy: 0.98408 | Loss: 0.829445124 |\n",
      "| Epoch:  9000 | Accuracy: 0.98408 | Loss: 0.829443634 |\n",
      "| Epoch:  9100 | Accuracy: 0.98408 | Loss: 0.829460025 |\n",
      "| Epoch:  9200 | Accuracy: 0.98408 | Loss: 0.830132365 |\n",
      "| Epoch:  9300 | Accuracy: 0.98408 | Loss: 0.829808354 |\n",
      "| Epoch:  9400 | Accuracy: 0.98408 | Loss: 0.829754829 |\n",
      "| Epoch:  9500 | Accuracy: 0.98408 | Loss: 0.829710722 |\n",
      "| Epoch:  9600 | Accuracy: 0.98408 | Loss: 0.829666853 |\n",
      "| Epoch:  9700 | Accuracy: 0.98453 | Loss: 0.829622209 |\n",
      "| Epoch:  9800 | Accuracy: 0.98453 | Loss: 0.829579055 |\n",
      "| Epoch:  9900 | Accuracy: 0.98453 | Loss: 0.829540730 |\n",
      "| Epoch: 10000 | Accuracy: 0.98453 | Loss: 0.829510272 |\n",
      "| Epoch: 10100 | Accuracy: 0.98453 | Loss: 0.829488516 |\n",
      "| Epoch: 10200 | Accuracy: 0.98453 | Loss: 0.829476595 |\n",
      "| Epoch: 10300 | Accuracy: 0.98499 | Loss: 0.829477787 |\n",
      "| Epoch: 10400 | Accuracy: 0.98408 | Loss: 0.829495847 |\n",
      "| Epoch: 10500 | Accuracy: 0.98408 | Loss: 0.829532027 |\n",
      "| Epoch: 10600 | Accuracy: 0.98408 | Loss: 0.829581559 |\n",
      "| Epoch: 10700 | Accuracy: 0.98408 | Loss: 0.829636335 |\n",
      "| Epoch: 10800 | Accuracy: 0.98408 | Loss: 0.829691172 |\n",
      "| Epoch: 10900 | Accuracy: 0.98362 | Loss: 0.829745173 |\n",
      "| Epoch: 11000 | Accuracy: 0.98362 | Loss: 0.829799294 |\n",
      "| Epoch: 11100 | Accuracy: 0.98362 | Loss: 0.829853415 |\n",
      "| Epoch: 11200 | Accuracy: 0.98317 | Loss: 0.829907656 |\n",
      "| Epoch: 11300 | Accuracy: 0.98317 | Loss: 0.829961658 |\n",
      "| Epoch: 11400 | Accuracy: 0.98317 | Loss: 0.830014586 |\n",
      "| Epoch: 11500 | Accuracy: 0.98317 | Loss: 0.830066085 |\n",
      "| Epoch: 11600 | Accuracy: 0.98362 | Loss: 0.830115557 |\n",
      "| Epoch: 11700 | Accuracy: 0.98362 | Loss: 0.830162883 |\n",
      "| Epoch: 11800 | Accuracy: 0.98362 | Loss: 0.830207825 |\n",
      "| Epoch: 11900 | Accuracy: 0.98362 | Loss: 0.830250442 |\n",
      "| Epoch: 12000 | Accuracy: 0.98362 | Loss: 0.830291033 |\n",
      "| Epoch: 12100 | Accuracy: 0.98362 | Loss: 0.830329955 |\n",
      "| Epoch: 12200 | Accuracy: 0.98362 | Loss: 0.830367327 |\n",
      "| Epoch: 12300 | Accuracy: 0.98362 | Loss: 0.830403507 |\n",
      "| Epoch: 12400 | Accuracy: 0.98362 | Loss: 0.830438793 |\n",
      "| Epoch: 12500 | Accuracy: 0.98362 | Loss: 0.830473483 |\n",
      "| Epoch: 12600 | Accuracy: 0.98362 | Loss: 0.830507755 |\n",
      "| Epoch: 12700 | Accuracy: 0.98362 | Loss: 0.830541730 |\n",
      "| Epoch: 12800 | Accuracy: 0.98362 | Loss: 0.830575764 |\n",
      "| Epoch: 12900 | Accuracy: 0.98362 | Loss: 0.830609858 |\n",
      "| Epoch: 13000 | Accuracy: 0.98408 | Loss: 0.830643952 |\n",
      "| Epoch: 13100 | Accuracy: 0.98408 | Loss: 0.830677986 |\n",
      "| Epoch: 13200 | Accuracy: 0.98408 | Loss: 0.830712378 |\n",
      "| Epoch: 13300 | Accuracy: 0.98408 | Loss: 0.830746531 |\n",
      "| Epoch: 13400 | Accuracy: 0.98408 | Loss: 0.830780506 |\n",
      "| Epoch: 13500 | Accuracy: 0.98453 | Loss: 0.830814242 |\n",
      "| Epoch: 13600 | Accuracy: 0.98453 | Loss: 0.830847502 |\n",
      "| Epoch: 13700 | Accuracy: 0.98453 | Loss: 0.830880225 |\n",
      "| Epoch: 13800 | Accuracy: 0.98499 | Loss: 0.830912232 |\n",
      "| Epoch: 13900 | Accuracy: 0.98499 | Loss: 0.830943227 |\n",
      "| Epoch: 14000 | Accuracy: 0.98499 | Loss: 0.830973148 |\n",
      "| Epoch: 14100 | Accuracy: 0.98499 | Loss: 0.831001818 |\n",
      "| Epoch: 14200 | Accuracy: 0.98499 | Loss: 0.831029177 |\n",
      "| Epoch: 14300 | Accuracy: 0.98499 | Loss: 0.831055343 |\n",
      "| Epoch: 14400 | Accuracy: 0.98499 | Loss: 0.831080198 |\n",
      "| Epoch: 14500 | Accuracy: 0.98499 | Loss: 0.831104100 |\n",
      "| Epoch: 14600 | Accuracy: 0.98499 | Loss: 0.831127226 |\n",
      "| Epoch: 14700 | Accuracy: 0.98499 | Loss: 0.831150293 |\n",
      "| Epoch: 14800 | Accuracy: 0.98499 | Loss: 0.831174314 |\n",
      "| Epoch: 14900 | Accuracy: 0.98499 | Loss: 0.831201375 |\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "train_loss_NN, test_loss_NN, parameter_NN = training.train_normal_nn(NN,\n",
    "                                                                     train_loader,\n",
    "                                                                     test_loader,\n",
    "                                                                     optimizer=optimizer_NN,\n",
    "                                                                     lossfunction=celoss,\n",
    "                                                                     Epoch=15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f23e9b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7809, tensor(0.8263))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAnF0lEQVR4nO3dd3wc9Z3/8ddnVyvJcrfk3iE0O2AbhIEDgiEUAwmEFM4ECIGAU0gupHCUJHCQu98ll/txhEsCOImPFEr4ASFcMMEOMSWFIjsGXLExBss2ltybZLXP748ZSatmtZVmPX4/H4/Vzn7LzGdmV5+dnfnurLk7IiISX4moAxARkZ6lRC8iEnNK9CIiMadELyISc0r0IiIxlxN1AK0pKiryCRMmRB2GiMhBY9GiRVvcfWhrdVmZ6CdMmEBJSUnUYYiIHDTM7N226nToRkQk5pToRURiToleRCTmsvIYvYhIZ1VXV1NaWkplZWXUofSo/Px8xowZQyqV6nAfJXoRiYXS0lL69+/PhAkTMLOow+kR7s7WrVspLS1l4sSJHe6nQzciEguVlZUUFhbGNskDmBmFhYWd/tTSbqI3s7FmttDMlpvZMjP7aittZpjZTjNbEt5uS6ubaWarzGyNmd3cqehERDohzkm+XlfWsSOHbmqAb7j7YjPrDywyswXuvrxZu5fc/SPNAkoCPwbOAUqB18zsqVb6ZsQ9z61mythBnHFkq98ZEBE5JLW7R+/um9x9cTi9G1gBjO7g/KcDa9x9rbtXAY8AF3c12Pb85Pk1/GXNlp6avYhIm3bs2MFPfvKTTve74IIL2LFjR+YDStOpY/RmNgGYBrzSSvUpZva6mT1jZpPDstHA+rQ2pbTxJmFms82sxMxKysvLOxNW4zww9EMqIhKFthJ9TU3NAfvNmzePQYMG9VBUgQ4nejPrBzwO3ODuu5pVLwbGu/sU4L+BJzsbiLvPcfdidy8eOrRrh17MQHleRKJw88038/bbbzN16lROPPFETj/9dC666CImTZoEwMc+9jFOOOEEJk+ezJw5cxr6TZgwgS1btrBu3TqOOeYYrrvuOiZPnsy5555LRUVFRmLr0PBKM0sRJPkH3f2J5vXpid/d55nZT8ysCNgAjE1rOiYs6xEJM5TnReSO/13G8o3N90e7Z9KoAdz+0clt1n/ve99j6dKlLFmyhOeff54LL7yQpUuXNgyDnDt3LkOGDKGiooITTzyRT3ziExQWFjaZx+rVq3n44Yf56U9/yqWXXsrjjz/OFVdc0e3YOzLqxoCfAyvc/a422owI22Fm08P5bgVeA44ws4lmlgvMAp7qdtRtxQrUaZdeRLLA9OnTm4x1v+eee5gyZQonn3wy69evZ/Xq1S36TJw4kalTpwJwwgknsG7duozE0pE9+lOBK4E3zWxJWHYrMA7A3e8DPgl80cxqgApglgcHy2vM7MvAs0ASmOvuyzISeWt06EZE4IB73r2lb9++DdPPP/88f/zjH/nb3/5GQUEBM2bMaHUsfF5eXsN0MpnsvUM37v5ngp3lA7X5EfCjNurmAfO6FF0nxX8ErYhkq/79+7N79+5W63bu3MngwYMpKChg5cqVvPzyy70aW6wugWCmUTciEo3CwkJOPfVUPvjBD9KnTx+GDx/eUDdz5kzuu+8+jjnmGI466ihOPvnkXo0tZokenYwVkcg89NBDrZbn5eXxzDPPtFpXfxy+qKiIpUuXNpR/85vfzFhcsbrWzfN1V3P2hnujDkNEJKvEKtHnUkPCq6MOQ0Qkq8Qq0XvDHxERqRezRJ9AmV5EpKmYJXowr4s6DBGRrBKrRP9k4mzW9T0u6jBERLJKrBL9j3Ku4o0BZ0Ydhogcgrp6mWKAu+++m3379mU4okaxSvQ5Xotp1I2IRCCbE32svjD1++prWbHxLOAXUYciIoeY9MsUn3POOQwbNoxHH32U/fv3c8kll3DHHXewd+9eLr30UkpLS6mtreU73/kOmzdvZuPGjZx55pkUFRWxcOHCjMcWq0Qf0KgbEQH+58KWZZM/BtOvg6p98OCnWtZP/TRMuxz2boVHP9O07uqnD7i49MsUz58/n8cee4xXX30Vd+eiiy7ixRdfpLy8nFGjRvH008G8du7cycCBA7nrrrtYuHAhRUVFXVzZA4vVoRvHUKIXkajNnz+f+fPnM23aNI4//nhWrlzJ6tWrOfbYY1mwYAE33XQTL730EgMHDuyVeGK1R+8YpouaiQgceA88t+DA9X0L292DPxB355ZbbuHzn/98i7rFixczb948vv3tb/PhD3+Y2267rcvL6ahY7dGjPXoRiUj6ZYrPO+885s6dy549ewDYsGEDZWVlbNy4kYKCAq644gpuvPFGFi9e3KJvT4jVHv3jqQvI6XsUp0QdiIgcctIvU3z++efz6U9/mlNOCbJRv379+PWvf82aNWu48cYbSSQSpFIp7r03uAjj7NmzmTlzJqNGjeqRk7GWjddvLy4u9pKSkk73O+MHC5k6dhA/nDWtB6ISkWy2YsUKjjnmmKjD6BWtrauZLXL34tbax2qPvr/vIVWbG3UYIiJZJVaJ/ucVN/DO5mKCn7kVERHQyVgRiZFsPBSdaV1Zx3YTvZmNNbOFZrbczJaZ2VdbaXO5mb1hZm+a2V/NbEpa3bqwfImZdf7Aeyc4BofAEy0iLeXn57N169ZYJ3t3Z+vWreTn53eqX0cO3dQA33D3xWbWH1hkZgvcfXlam3eAM9x9u5mdD8wBTkqrP9Pdt3Qqsi5wDNMevcghacyYMZSWllJeXh51KD0qPz+fMWPGdKpPu4ne3TcBm8Lp3Wa2AhgNLE9r89e0Li8DnYsiQ7RHL3LoSqVSTJw4MeowslKnjtGb2QRgGvDKAZp9Dkj/uXMH5pvZIjObfYB5zzazEjMr6eo78uN5H2NxvzO61FdEJK46POrGzPoBjwM3uPuuNtqcSZDoT0srPs3dN5jZMGCBma109xeb93X3OQSHfCguLu7Sbvnv8y5kQt+CrnQVEYmtDu3Rm1mKIMk/6O5PtNHmOOBnwMXuvrW+3N03hPdlwG+B6d0Nui1FvpW+NTt6avYiIgeljoy6MeDnwAp3v6uNNuOAJ4Ar3f2ttPK+4QlczKwvcC6wNBOBt+b7e77FrC3/3VOzFxE5KHXk0M2pwJXAm2a2JCy7FRgH4O73AbcBhcBPgvcFasKv4g4HfhuW5QAPufsfMrkC6YJRNyIikq4jo27+DAfOn+5+LXBtK+VrgSkte/Qgr+vVxYmIZLtYfTO2zmK1OiIiGRGzzGgY2qMXEUkXq4uaPdbnU1jBIFq9TqeIyCEqVon+xfwzGZSvyxSLiKSLVaIfUbeJgprOXexHRCTuYpXob9r1f9ixbxjw0ahDERHJGjE8GauLmomIpItVonf98IiISAuxS/SmyxSLiDQRq0SPaY9eRKS5WJ2Mfazv5dQmUkyNOhARkSwSq0S/uM9JuqiZiEgzsUr046rXUYsBp0QdiohI1ohVop+984dUWj4wK+pQRESyRqxOxrpOxoqItBCvRK9x9CIiLcQq0aNx9CIiLcQr0ZsugSAi0lysTsY+PuAzVFTV8q9RByIikkVilehX9ZnKTqqjDkNEJKu0e+jGzMaa2UIzW25my8zsq620MTO7x8zWmNkbZnZ8Wt1VZrY6vF2V6RVIN7HqLY6oWtmTixAROeh0ZI++BviGuy82s/7AIjNb4O7L09qcDxwR3k4C7gVOMrMhwO1AMcFwmEVm9pS7b8/oWoQu3fEzEjWVwOd6YvYiIgeldvfo3X2Tuy8Op3cDK4DRzZpdDPzSAy8Dg8xsJHAesMDdt4XJfQEwM6Nr0ISGV4qINNepUTdmNgGYBrzSrGo0sD7tcWlY1lZ5a/OebWYlZlZSXl7embDS5wIaXiki0kSHE72Z9QMeB25w912ZDsTd57h7sbsXDx06tGvzMHRRMxGRZjqU6M0sRZDkH3T3J1ppsgEYm/Z4TFjWVnkPSaBDNyIiTXVk1I0BPwdWuPtdbTR7CvhMOPrmZGCnu28CngXONbPBZjYYODcs6xFPDrma+/tc11OzFxE5KHVk1M2pwJXAm2a2JCy7FRgH4O73AfOAC4A1wD7g6rBum5l9F3gt7Henu2/LWPTNvJd3FO/l7Oup2YuIHJTaTfTu/mfaOfTt7g5c30bdXGBul6LrpMP3L2Nw9S7gQ72xOBGRg0Ksvhl7/vaH6FNZBnwl6lBERLKGLmomIhJzsUr0Hq/VERHJiFhlRscw6qIOQ0Qkq8Qq0QeHbkREJF2sTsb+vuha3t28jZ9GHYiISBaJVaIvyxvP6sTAqMMQEckqsUr0H6hYwoCa94Ezow5FRCRrxCrRn779dwypegu4JepQRESyRqxOxroZCY26ERFpIl6JPl6rIyKSEbHKjG4J7dGLiDQTv0TvSvQiIulidTJ2wbDP8freC/hN1IGIiGSRWCX6XXkjWGex+pAiItJtsUr0h+1dQt+a5cDZUYciIpI1YrX7e9yuP/HlugejDkNEJKvEKtEbCRLURh2GiEhWiVWid0vqh0dERJqJVaInkSCp4ZUiIk20ezLWzOYCHwHK3P2DrdTfCFyeNr9jgKHuvs3M1gG7gVqgxt2LMxV4a9wS2qMXEWmmI3v0DwAz26p09x+4+1R3n0pwNbEX3H1bWpMzw/oeTfIAr4y6igtr/7OnFyMiclBpN9G7+4vAtvbahS4DHu5WRN2wP3cQpV4U1eJFRLJSxo7Rm1kBwZ7/42nFDsw3s0VmNrud/rPNrMTMSsrLy7sUw/jdf2e2PdmlviIicZXJk7EfBf7S7LDNae5+PHA+cL2Zfaitzu4+x92L3b146NChXQpg/K4SbszRBRBERNJlMtHPotlhG3ffEN6XAb8FpmdweS2Flz+oq9VYehGRehlJ9GY2EDgD+F1aWV8z618/DZwLLM3E8toOJEz0dUr0IiL1OjK88mFgBlBkZqXA7UAKwN3vC5tdAsx3971pXYcDvzWz+uU85O5/yFzorcWaBKC2toacVG5PLkpE5KDRbqJ398s60OYBgmGY6WVrgSldDawrPBEkeq/Tl6ZEROrF6puxy8f8I1Mr76c2kRd1KCIiWSNWid5TBeygvy5rJiKSJlaJfsTO17kx5xF8/76oQxERyRqxSvRFu1dwfc5T1FVXRB2KiEjWiFWit0T9OPqaiCMREckesUr0mEbdiIg0F6tE37BHry9MiYg0iFWir9+jV6IXEWkUq0T/3tiLOaLyl1QXjIw6FBGRrBGrRJ/ISVFNDjpCLyLSKFaJfvDO5fxLzgP4nq5dz15EJI5ilej773uXz+bMxyp3RB2KiEjWiFWit/Ayxa6TsSIiDeKV6BuuXqkvTImI1ItVom8YXqlfmBIRaRCrRG/JHKo8SV2dRx2KiEjWiFWi3z7mLI7c/yv2FU6OOhQRkawRq0Qf/mwhta49ehGRerFK9P12reU/U/eRu31N1KGIiGSNWCX6vP3b+GTyRXL2vh91KCIiWaPdRG9mc82szMyWtlE/w8x2mtmS8HZbWt1MM1tlZmvM7OZMBt6qnBQAXlvd44sSETlYdGSP/gFgZjttXnL3qeHtTgAzSwI/Bs4HJgGXmdmk7gTbnkROLgBeU9WTixEROai0m+jd/UVgWxfmPR1Y4+5r3b0KeAS4uAvz6bBkuEdfV6tELyJSL1PH6E8xs9fN7Bkzqx/bOBpYn9amNCxrlZnNNrMSMyspL+/aRckSqT5s937U1FmX+ouIxFEmEv1iYLy7TwH+G3iyKzNx9znuXuzuxUOHDu1SIF54ONP2z2HTyLO71F9EJI66nejdfZe77wmn5wEpMysCNgBj05qOCct6TE74U4JVtboivYhIvW4nejMbYeE3lcxsejjPrcBrwBFmNtHMcoFZwFPdXd6B5Nbs5t7Uf1G48cWeXIyIyEElp70GZvYwMAMoMrNS4HYgBeDu9wGfBL5oZjVABTDL3R2oMbMvA88CSWCuuy/rkbUIpayO85OvsWjPh3tyMSIiB5V2E727X9ZO/Y+AH7VRNw+Y17XQOi8nFQ6v1Dh6EZEGsfpmbCo3L5jQ8EoRkQaxSvQ5qfpErz16EZF68Ur0OTmsrxtKZaIg6lBERLJGrBJ9Kpng9KofUjLygKcVREQOKbFK9MmEkTCoqdX16EVE6sUq0QP8OPVDjtv4SNRhiIhkjdgl+hNtJYV73446DBGRrBG7RF9jOVhdTdRhiIhkjfglenKwOg2vFBGpF7tEX2W5JOv2Rx2GiEjWaPcSCAeb9xJjSCQLow5DRCRrxC7Rf7fgZo4q6s+Hog5ERCRLxO7QTX4qyf5qXY9eRKRe7Pbor638BcMqttDFH7oSEYmd2CX6kb6ZsVVrow5DRCRrxO7QTW0in5Rr1I2ISL3YJfq6nHxSruvRi4jUi12ir03mkac9ehGRBrFL9Dv7jGMZH4g6DBGRrBG7RP/6iE/y2brvRB2GiEjWaDfRm9lcMyszs6Vt1F9uZm+Y2Ztm9lczm5JWty4sX2JmJZkMvC35qQSVNRpHLyJSryN79A8AMw9Q/w5whrsfC3wXmNOs/kx3n+ruxV0LsXOO2/Ec83O+TvXu8t5YnIhI1ms30bv7i8C2A9T/1d23hw9fBsZkKLYu6cN+Dk9sYv++3VGGISKSNTJ9jP5zwDNpjx2Yb2aLzGz2gTqa2WwzKzGzkvLyru+NJ3L7AFBVsa/L8xARiZOMfTPWzM4kSPSnpRWf5u4bzGwYsMDMVoafEFpw9zmEh32Ki4u7/KOvllsAQFWl9uhFRCBDe/RmdhzwM+Bid99aX+7uG8L7MuC3wPRMLO+AseQPAKC2YmdPL0pE5KDQ7URvZuOAJ4Ar3f2ttPK+Zta/fho4F2h15E4mWb8RLKydwj4KenpRIiIHhXYP3ZjZw8AMoMjMSoHbgRSAu98H3AYUAj8xM4CacITNcOC3YVkO8JC7/6EH1qGJxLAjubr6Jh7sP4kjenphIiIHgXYTvbtf1k79tcC1rZSvBaa07NGzBuSnANhdqd+NFRGBGH4ztn+u8de8LzNy6U+jDkVEJCvELtEPKMhnMHuwfWVRhyIikhVil+j75eewmwJs/66oQxERyQqxS/TJhLGHAhJVGkcvIgIxTPQAexP9SFVpj15EBGL4m7EAJbnTKczN4cioAxERyQKxTPTPDL4CM7go6kBERLJALA/dFPbLZdueSvAuXzJHRCQ2YpnoZ1bO45ndH4fKHVGHIiISuVgm+lTBQHKoo2aXxtKLiMQy0ecOGAbA7m2bIo5ERCR6sUz0+QOHA7B32+aIIxERiV4sE33fISMBqNjxfsSRiIhEL5aJfkDhcH5Vczbv546POhQRkcjFMtEXDejHd2quYVX+cVGHIiISuVgm+gF9cshPwp5tOnQjIhLLRG9m/LDPT7nyzc9GHYqISORimegBKgpGM6imHGqqog5FRCRSsU30tYPGk6QOdrwXdSgiIpGKbaJPDJsEwN73lkQbiIhIxDqU6M1srpmVmdnSNurNzO4xszVm9oaZHZ9Wd5WZrQ5vV2Uq8PYMnDCFak+y651FvbVIEZGs1NE9+geAmQeoPx84IrzNBu4FMLMhwO3AScB04HYzG9zVYDtj0tihfLfmCv7e56TeWJyISNbqUKJ39xeBbQdocjHwSw+8DAwys5HAecACd9/m7tuBBRz4DSNjhg/I4+n8j7Jw78TeWJyISNbK1DH60cD6tMelYVlb5S2Y2WwzKzGzkvLy8m4HZGYcO7IPtu7PsHNDt+cnInKwypqTse4+x92L3b146NChGZnnaSON/9h7KxVLHsvI/EREDkaZSvQbgLFpj8eEZW2V94qpk49hTd0o9i77Q28tUkQk62Qq0T8FfCYcfXMysNPdNwHPAuea2eDwJOy5YVmvmDJ2EM/ZSQwuewX2bumtxYqIZJWODq98GPgbcJSZlZrZ58zsC2b2hbDJPGAtsAb4KfAlAHffBnwXeC283RmW9YpUMkH5+AtJUkvt0id6a7EiIlklpyON3P2yduoduL6NurnA3M6HlhnFJ57GinXjGPb60xSeNDuqMEREItOhRH8wm3H0MC5J3MSEvA8Eg/tFRA4xWTPqpqfkp5Kcc+p0nlmxldXvlkJ1RdQhiYj0qtgneoCr/2ECo/MrKfzF6fjTXwf3qEMSEek1h0SiH9w3l+vPP5FfVs3AljwEf7gF6mqjDktEpFccEokeYNaJY1l11PX8vOZ8eOVeeOhS2L056rBERHrcIZPoEwnjrn+cxrzR/8S3q6+hZu1L8NydUYclItLjDplED9AnN8mvPjeddw+bxXkV/8odlf/I7spq2LwMVv0B6uqiDlFEJONiP7yyuYLcHOZ+9kT+a8FA7n3hbf53zQs8NuznTNg4D4qOhOM/A0d/BIboqpciEg+H1B59vVQywT/PPJonv3Qq4wsLOHvtLG7PuYGyqhTM/zbcMxUemtXYYe0LULYSavZHFrOISFcdcnv06aaMHcRjXziFhavKuP+FYUx/ZzqH52zh+lGr+EC/kYzZW8WQPjnw8Cyo3geWgAFjYMAoOPaTMP26YKjmsidg0AQoPAz69MrvqoiIdNghneghuG79WUcP56yjh/NG6Q4eLVnPvywZwa73auCvCzhyaAHnjLqLaQVbOTyxiaLqjfTdX0aitjqYQcV2eOyaxhmOOwWu0dUyRSR7mGfhl4eKi4u9pKQksuVX19bxRulO/rpmC0vW72DFpl1s3FnZUG8GIwbkM25IARMG53J8wRaOzNvCMavnkF+2BD7/Eow8LtjbN4tsPUTk0GFmi9y9uLW6Q36PvjWpZIITxg/mhPGNh2F27qtmddlu3tu2r+G2fts+/rR6O7/ZXQMMYqxdxbz8NfTZsZ6ckcfB6vnw+LXQfwT0GQJ5/YPbmbdC0RGweTmsXRiU5faDVB/IyYMx0yGvH+zbFnxiyMkPbql8SKQgmdIbSNTcobYavBZqq2DVM3DMRVBTCV4X3jy47z8ieL4qtkPV3sb+9QaFP9mwdytU7alfQHBnCRg0LpjevRmq9zbtm0jC4AnB9K6NULUv6FvfJplqHFiw/d20S4CE9Tn5jfVb3w7jT5t/bt/G+rKVwbqSVp83oLH+/TehrqZp/4IhjfFtWBzWpdX3LQrq6+pgQ0nLbTNgZLD+tdVQWtLYt77NoHHB9quuDPo39A3vhxwOA0fD/j2tz3/o0cEyKnbAhkVN+wIMPxb6Dw+em42LW/YffXywDrvfh41LWvYfe1KwDXash/ffaNl/4umQPxC2rYX3l8LhZwb5IMOU6DtoYEGK4glDKJ4wpEXdrspq1pbv5U8ry/iH5+7maxvH8NEx+ynsN5LE1E/D7k3BC2nfVti+LvhnAih9FZ69teXCvvQKDDsaXn8Enr2lZf3Xlgcv3hd+AC98L0gGlgz+6TH4+rLgxfOnf4NX7mvZ/6Z3IZEIviH89183rcvJhxtXB9NPfQWWPdm0vm8R/NPfg+nHroG35jetHzwBvvjnYPrBT8G6vzStHz4Zrl0QTM+dmfbPERp3Enzmd8H0vafB1jCW+n+OD3wYLns4mL77uGDbppt0MXziZ8H09yfC/t1N66ddDh/9YTB9Z1GQiNOd/EU479+ChPnvrfzq5YduDN6od78Pdx3dtO71R4I37ua+tTl4k1747/Dq/U3rEjlw29ZgesF3YMmDTevzB8HN7wbTz9wIy3/XtH7gWPja0mD6d1+Gt59rWj/0aLj+lWD6ietg/StN60cXw3Vhn99cCWXLmtYfNqPx+XjoU7Djvab1R38EZoUx//Li4DWebsplcEn4Gpw7E2qbDWg48Vq48P8Gb5g/P4cWTr0BzrkjeB7/p5Wfmz7r28FzsrcMHriwZf3M78PJX4Cd64P4mrv4xzDtCtiyGn798Zb1n3oAJl8C778OD36yZf3lj8MRZ8P6V+HRK1vWX/MsjDsZ1r0ET36xZf0X/gIjBsKa52DeN+H612CoEn1WGpCfYurYQUwaOYDfLdnAnQtKuXNBKamkMaz/eYwYmE9h31wGDk4xsE+KgctSDHxnHQPzz2LQxxfRjwr6UkG+VZNPNYmcYfSprKbPYWeRc8n9wRtDzf7gvrYK8gcECx53Epz61eByDl7buAeZzA3qR00LXsRtGTu9ZVki7SUx/rTgk0a63L6N04fNgH4jmtYXpJ2MPvK8YMhquv4jG6cnfQzGnNi0fvD4xunjLoV96T8YY8EnoXonXNUykQ+b3Dh90udbjpQaNa1x+tSv0sLYk4L7RA6c/o2W9eP/IbjPHxgkGUvCyqeDvcUz/hmOOj9444XwDdgat+mxn4QRH2y6PumfzKZdCeNPTau2xucSYPpsOOqCxr4AuQVN12fKZY19IdjjrnfmrcGnxPT5pw8eOO9f07Zn2L9vUWP9R+5u/ERQP//05/+SOVBX3bT/gFGN9bMebHzDru8/cEz4OAlXPN7Ytr7/oPD1kNcfrnyyaV+s8dNC32Fw1f827WsGg8NPG4PGwdXPtJx/4eHB/bCj4Zq0nZb6ZRR+ILgffQJcm/4m2qz/xNPhurQ3+Yb+4ev1yJnw+Rfb7j/548H5vfpPbxmmY/QZtq+qhkXvbmdN2R4279pP2a5KNu+uZMvuKnZVVrOzopp9VR2/zk4qaeSnkuSnkuQmE+TmJEgljVTDdILcZNOy4HGCVE4rZWHbhBnJhJFIGEkzkglIJhIkEzTUJS29vnE6kaChrP6WsJbTRvB6N6zhdW8WzD+93CDIeWmPzZr1T7RRnjbf5v0TFtyLHAp0jL4XFeTmcPoRQzn9iLZ/4Lyqpq4h6e+urKGiqpbK6loqqmupqAruK8PpfeF9ZXUt1bVOdW0dVTV1wX1tcF9RXcvOiqZl1TUeTNcEZVW1dYf0RTvbegOhoTx83KxPk8etztfabdO8sEPzydCyW77PHXg5rc2n9TZdmU/7b7ot1rsLy+7N5ynThhTk8ugXTsn4fJXoI5Cbk6CoXx5F/fJ6dbm1dR68SdTVUVfn1NY5te7U1RHeOzVheZ2H9WnTwT0t6hvnE9zX13t4TtABdw9OUTlBHfV13tCG9PImbcLHzdqnP6ZJm8a6Om8231b6U7/8NM0/6bb2JtmyT2tt2p9Piz7Nl91qmwMvp/U2B65vrVWr69RDy24xnw5t865sq9batD+f1gszq39+z6RkJfpDSDJh9MlN0odk1KGISC86JC+BICJyKOlQojezmWa2yszWmNnNrdT/l5ktCW9vmdmOtLratLqnMhi7iIh0QLuHbswsCfwYOAcoBV4zs6fcfXl9G3f/Wlr7rwBpY9iocPepGYtYREQ6pSN79NOBNe6+1t2rgEeAVr550OAy4OFMBCciIt3XkUQ/Glif9rg0LGvBzMYDE4E/pRXnm1mJmb1sZh9rayFmNjtsV1JeXt6BsEREpCMyfTJ2FvCYu6d/I2h8OIj/08DdZnZ4ax3dfY67F7t78dChbY9BFxGRzulIot8AjE17PCYsa80smh22cfcN4f1a4HmaHr8XEZEe1pFE/xpwhJlNNLNcgmTeYvSMmR0NDAb+llY22Mzywuki4FRgefO+IiLSc9oddePuNWb2ZeBZIAnMdfdlZnYnUOLu9Ul/FvCIN/2K2THA/WZWR/Cm8r300TptWbRo0RYze7ezKxMqAra02yo62R4fKMZMyPb4IPtjzPb4ILtiHN9WRVZe1Kw7zKykrQv7ZINsjw8UYyZke3yQ/TFme3xwcMQI+masiEjsKdGLiMRcHBP9nKgDaEe2xweKMROyPT7I/hizPT44OGKM3zF6ERFpKo579CIikkaJXkQk5mKT6Nu7lHIPL3usmS00s+VmtszMvhqWDzGzBWa2OrwfHJabmd0TxvqGmR2fNq+rwvarzeyqDMeZNLO/m9nvw8cTzeyVMI7fhF+Iw8zywsdrwvoJafO4JSxfZWbnZTi+QWb2mJmtNLMVZnZKNm1DM/ta+PwuNbOHzSw/6m1oZnPNrMzMlqaVZWybmdkJZvZm2Oces87/ll4bMf4gfJ7fMLPfmtmgtLpWt09b/+NtPQfdiS+t7htm5hZ84TOybdhtwc+vHdw3gi9yvQ0cBuQCrwOTenH5I4Hjw+n+wFvAJOA/gJvD8puB74fTFwDPEPws5cnAK2H5EGBteD84nB6cwTi/DjwE/D58/CgwK5y+D/hiOP0l4L5wehbwm3B6Urht8wguXvc2kMxgfL8Arg2nc4FB2bINCS7k9w7QJ23bfTbqbQh8CDgeWJpWlrFtBrwatrWw7/kZivFcICec/n5ajK1uHw7wP97Wc9Cd+MLysQRfFH0XKIpyG3b79dvbC+yRlYBTgGfTHt8C3BJhPL8juH7/KmBkWDYSWBVO3w9cltZ+VVh/GXB/WnmTdt2MaQzwHHAW8PvwRbcl7Z+tYRuGL+5TwumcsJ01367p7TIQ30CCRGrNyrNiG9J4Fdch4Tb5PXBeNmxDYAJNk2hGtllYtzKtvEm77sTYrO4S4MFwutXtQxv/4wd6HXc3PuAxYAqwjsZEH9k27M4tLoduOnwp5Z4WfkSfBrwCDHf3TWHV+8DwcLqteHtyPe4G/hmoCx8XAjvcvaaVZTXEEdbvDNv3ZHwTgXLgfyw4vPQzM+tLlmxDDy7O95/Ae8Amgm2yiOzahvUytc1Gh9M9GSvANQR7ul2J8UCv4y4zs4uBDe7+erOqbN2GBxSXRJ8VzKwf8Dhwg7vvSq/z4O08krGsZvYRoMzdF0Wx/A7KIfj4fK+7TwP2Ehx2aBDxNhxM8IM7E4FRQF9gZhSxdEaU26wjzOxbQA3wYNSx1DOzAuBW4LaoY8mUuCT6zlxKuUeYWYogyT/o7k+ExZvNbGRYPxIoC8vbiren1uNU4CIzW0fwC2FnAT8EBplZ/YXt0pfVEEdYPxDY2oPxQbCnU+rur4SPHyNI/NmyDc8G3nH3cnevBp4g2K7ZtA3rZWqbbQineyRWM/ss8BHg8vANqSsxbqXt56CrDid4Q389/J8ZAyw2sxFdiK9Ht2GH9faxop64EewNriV4cupP1EzuxeUb8Evg7mblP6DpSbH/CKcvpOkJnVfD8iEEx6kHh7d3gCEZjnUGjSdj/x9NT2J9KZy+nqYnEh8NpyfT9ETZWjJ7MvYl4Khw+l/C7ZcV2xA4CVgGFITL/AXwlWzYhrQ8Rp+xbUbLE4kXZCjGmQSXLB/arF2r24cD/I+39Rx0J75mdetoPEYf2Tbs1muktxfYYysSnA1/i+DM/Ld6edmnEXw8fgNYEt4uIDh++BywGvhj2hNvBD+4/jbwJlCcNq9rgDXh7eoeiHUGjYn+sPBFuCb8Z8kLy/PDx2vC+sPS+n8rjHsVGR49AEwFSsLt+GT4D5M12xC4A1gJLAV+FSajSLchwQ/9bAKqCT4VfS6T2wwoDtf3beBHNDtZ3o0Y1xAc067/f7mvve1DG//jbT0H3YmvWf06GhN9JNuwuzddAkFEJObicoxeRETaoEQvIhJzSvQiIjGnRC8iEnNK9CIiMadELyISc0r0IiIx9/8Bu7Jd2DObxIAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_NN, '-', label='train')\n",
    "plt.plot(test_loss_NN, '--', label='test')\n",
    "plt.legend()\n",
    "best = np.argmin(test_loss_NN)\n",
    "best, test_loss_NN[best]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3366f4b5",
   "metadata": {},
   "source": [
    "## save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f68d2337",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./pendigitresult/NN_16.p', 'wb') as f:\n",
    "    pickle.dump(NN, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9192ad68",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcfe8799",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./pendigitresult/NN_16.p', 'rb') as f:\n",
    "    NN = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c45f3e6",
   "metadata": {},
   "source": [
    "## evalutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebe6060d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9854479308776717\n"
     ]
    }
   ],
   "source": [
    "for x_valid, y_valid in valid_loader:\n",
    "    prediction_valid = NN(x_valid)\n",
    "    p = torch.argmax(prediction_valid, 1)\n",
    "    pred_y = p.data.numpy().squeeze()\n",
    "    acc_valid = sum(pred_y == y_valid.numpy()) / y_valid.shape[0]\n",
    "print(acc_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00492b19",
   "metadata": {},
   "source": [
    "# PNN\n",
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef8515ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): PNNLayer()\n",
       "  (1): PNNLayer()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PNN = torch.nn.Sequential(pnn.PNNLayer(N_features, N_Hidden, age_generator),\n",
    "                          pnn.PNNLayer(N_Hidden, N_class, age_generator))\n",
    "optimizer_PNN = torch.optim.Adam(PNN.parameters(), lr=0.01)\n",
    "PNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "430b5fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3df8bbc76e704d7ab39cebbb773831dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch:     0 | Accuracy: 0.10328 | Loss: 1.395962777 |\n",
      "| Epoch:   100 | Accuracy: 0.74886 | Loss: 0.602397839 |\n",
      "| Epoch:   200 | Accuracy: 0.77070 | Loss: 0.416422436 |\n",
      "| Epoch:   300 | Accuracy: 0.86442 | Loss: 0.261196786 |\n",
      "| Epoch:   400 | Accuracy: 0.89354 | Loss: 0.192623468 |\n",
      "| Epoch:   500 | Accuracy: 0.92630 | Loss: 0.161237013 |\n",
      "| Epoch:   600 | Accuracy: 0.93949 | Loss: 0.143261454 |\n",
      "| Epoch:   700 | Accuracy: 0.94359 | Loss: 0.131893629 |\n",
      "| Epoch:   800 | Accuracy: 0.94859 | Loss: 0.123251981 |\n",
      "| Epoch:   900 | Accuracy: 0.95132 | Loss: 0.116093401 |\n",
      "| Epoch:  1000 | Accuracy: 0.95314 | Loss: 0.111037101 |\n",
      "| Epoch:  1100 | Accuracy: 0.95314 | Loss: 0.107315043 |\n",
      "| Epoch:  1200 | Accuracy: 0.95450 | Loss: 0.104318707 |\n",
      "| Epoch:  1300 | Accuracy: 0.95359 | Loss: 0.101704803 |\n",
      "| Epoch:  1400 | Accuracy: 0.95405 | Loss: 0.099584756 |\n",
      "| Epoch:  1500 | Accuracy: 0.95678 | Loss: 0.097210446 |\n",
      "| Epoch:  1600 | Accuracy: 0.95632 | Loss: 0.094913234 |\n",
      "| Epoch:  1700 | Accuracy: 0.95769 | Loss: 0.093027085 |\n",
      "| Epoch:  1800 | Accuracy: 0.95769 | Loss: 0.091574521 |\n",
      "| Epoch:  1900 | Accuracy: 0.95723 | Loss: 0.090563535 |\n",
      "| Epoch:  2000 | Accuracy: 0.95678 | Loss: 0.089374064 |\n",
      "| Epoch:  2100 | Accuracy: 0.95723 | Loss: 0.088358371 |\n",
      "| Epoch:  2200 | Accuracy: 0.95769 | Loss: 0.087601126 |\n",
      "| Epoch:  2300 | Accuracy: 0.95905 | Loss: 0.086541868 |\n",
      "| Epoch:  2400 | Accuracy: 0.95814 | Loss: 0.085700533 |\n",
      "| Epoch:  2500 | Accuracy: 0.95951 | Loss: 0.084699469 |\n",
      "| Epoch:  2600 | Accuracy: 0.95951 | Loss: 0.083761732 |\n",
      "| Epoch:  2700 | Accuracy: 0.95996 | Loss: 0.082838354 |\n",
      "| Epoch:  2800 | Accuracy: 0.96178 | Loss: 0.081793943 |\n",
      "| Epoch:  2900 | Accuracy: 0.96178 | Loss: 0.080995197 |\n",
      "| Epoch:  3000 | Accuracy: 0.96224 | Loss: 0.080249571 |\n",
      "| Epoch:  3100 | Accuracy: 0.96269 | Loss: 0.079446444 |\n",
      "| Epoch:  3200 | Accuracy: 0.96497 | Loss: 0.078563228 |\n",
      "| Epoch:  3300 | Accuracy: 0.96588 | Loss: 0.077875117 |\n",
      "| Epoch:  3400 | Accuracy: 0.96724 | Loss: 0.077326126 |\n",
      "| Epoch:  3500 | Accuracy: 0.96770 | Loss: 0.076507104 |\n",
      "| Epoch:  3600 | Accuracy: 0.96861 | Loss: 0.075871875 |\n",
      "| Epoch:  3700 | Accuracy: 0.96861 | Loss: 0.074844843 |\n",
      "| Epoch:  3800 | Accuracy: 0.96952 | Loss: 0.074090654 |\n",
      "| Epoch:  3900 | Accuracy: 0.96906 | Loss: 0.073487211 |\n",
      "| Epoch:  4000 | Accuracy: 0.96997 | Loss: 0.073049051 |\n",
      "| Epoch:  4100 | Accuracy: 0.96997 | Loss: 0.072314240 |\n",
      "| Epoch:  4200 | Accuracy: 0.96952 | Loss: 0.071768178 |\n",
      "| Epoch:  4300 | Accuracy: 0.96997 | Loss: 0.071393630 |\n",
      "| Epoch:  4400 | Accuracy: 0.96997 | Loss: 0.070930540 |\n",
      "| Epoch:  4500 | Accuracy: 0.96952 | Loss: 0.070674166 |\n",
      "| Epoch:  4600 | Accuracy: 0.96906 | Loss: 0.070471129 |\n",
      "| Epoch:  4700 | Accuracy: 0.96997 | Loss: 0.070284169 |\n",
      "| Epoch:  4800 | Accuracy: 0.96952 | Loss: 0.070058410 |\n",
      "| Epoch:  4900 | Accuracy: 0.96952 | Loss: 0.069929815 |\n",
      "| Epoch:  5000 | Accuracy: 0.97043 | Loss: 0.069731148 |\n",
      "| Epoch:  5100 | Accuracy: 0.97043 | Loss: 0.069589059 |\n",
      "| Epoch:  5200 | Accuracy: 0.96997 | Loss: 0.069457487 |\n",
      "| Epoch:  5300 | Accuracy: 0.96997 | Loss: 0.069491335 |\n",
      "| Epoch:  5400 | Accuracy: 0.96997 | Loss: 0.069325927 |\n",
      "| Epoch:  5500 | Accuracy: 0.97043 | Loss: 0.069078319 |\n",
      "| Epoch:  5600 | Accuracy: 0.96997 | Loss: 0.069075220 |\n",
      "| Epoch:  5700 | Accuracy: 0.97043 | Loss: 0.069011351 |\n",
      "| Epoch:  5800 | Accuracy: 0.97043 | Loss: 0.068763118 |\n",
      "| Epoch:  5900 | Accuracy: 0.97043 | Loss: 0.068720619 |\n",
      "| Epoch:  6000 | Accuracy: 0.97134 | Loss: 0.068535234 |\n",
      "| Epoch:  6100 | Accuracy: 0.97134 | Loss: 0.068270580 |\n",
      "| Epoch:  6200 | Accuracy: 0.97134 | Loss: 0.068183957 |\n",
      "| Epoch:  6300 | Accuracy: 0.97134 | Loss: 0.067931434 |\n",
      "| Epoch:  6400 | Accuracy: 0.97225 | Loss: 0.067788208 |\n",
      "| Epoch:  6500 | Accuracy: 0.97179 | Loss: 0.067645604 |\n",
      "| Epoch:  6600 | Accuracy: 0.97179 | Loss: 0.067385217 |\n",
      "| Epoch:  6700 | Accuracy: 0.97134 | Loss: 0.067216080 |\n",
      "| Epoch:  6800 | Accuracy: 0.97134 | Loss: 0.067136433 |\n",
      "| Epoch:  6900 | Accuracy: 0.97179 | Loss: 0.067141581 |\n",
      "| Epoch:  7000 | Accuracy: 0.97179 | Loss: 0.067199877 |\n",
      "| Epoch:  7100 | Accuracy: 0.97225 | Loss: 0.067172089 |\n",
      "| Epoch:  7200 | Accuracy: 0.97179 | Loss: 0.067392770 |\n",
      "| Epoch:  7300 | Accuracy: 0.97179 | Loss: 0.067419990 |\n",
      "| Epoch:  7400 | Accuracy: 0.97179 | Loss: 0.067447969 |\n",
      "| Epoch:  7500 | Accuracy: 0.97134 | Loss: 0.067538019 |\n",
      "| Epoch:  7600 | Accuracy: 0.97134 | Loss: 0.067454401 |\n",
      "| Epoch:  7700 | Accuracy: 0.97088 | Loss: 0.067497260 |\n",
      "| Epoch:  7800 | Accuracy: 0.97134 | Loss: 0.067586937 |\n",
      "| Epoch:  7900 | Accuracy: 0.97134 | Loss: 0.067611656 |\n",
      "| Epoch:  8000 | Accuracy: 0.97134 | Loss: 0.067688367 |\n",
      "| Epoch:  8100 | Accuracy: 0.97134 | Loss: 0.067612501 |\n",
      "| Epoch:  8200 | Accuracy: 0.97134 | Loss: 0.067710094 |\n",
      "| Epoch:  8300 | Accuracy: 0.97088 | Loss: 0.067611580 |\n",
      "| Epoch:  8400 | Accuracy: 0.97134 | Loss: 0.067593236 |\n",
      "| Epoch:  8500 | Accuracy: 0.97088 | Loss: 0.067673581 |\n",
      "| Epoch:  8600 | Accuracy: 0.97043 | Loss: 0.067783995 |\n",
      "| Epoch:  8700 | Accuracy: 0.97088 | Loss: 0.067796819 |\n",
      "| Epoch:  8800 | Accuracy: 0.97088 | Loss: 0.067857562 |\n",
      "| Epoch:  8900 | Accuracy: 0.96997 | Loss: 0.067794164 |\n",
      "| Epoch:  9000 | Accuracy: 0.97043 | Loss: 0.067814819 |\n",
      "| Epoch:  9100 | Accuracy: 0.96997 | Loss: 0.067973038 |\n",
      "| Epoch:  9200 | Accuracy: 0.97043 | Loss: 0.067946162 |\n",
      "| Epoch:  9300 | Accuracy: 0.97043 | Loss: 0.068056205 |\n",
      "| Epoch:  9400 | Accuracy: 0.97088 | Loss: 0.068084618 |\n",
      "| Epoch:  9500 | Accuracy: 0.96952 | Loss: 0.068063070 |\n",
      "| Epoch:  9600 | Accuracy: 0.97088 | Loss: 0.068361750 |\n",
      "| Epoch:  9700 | Accuracy: 0.97043 | Loss: 0.068236030 |\n",
      "| Epoch:  9800 | Accuracy: 0.96997 | Loss: 0.068322606 |\n",
      "| Epoch:  9900 | Accuracy: 0.97134 | Loss: 0.068455148 |\n",
      "| Epoch: 10000 | Accuracy: 0.97088 | Loss: 0.068473923 |\n",
      "| Epoch: 10100 | Accuracy: 0.97134 | Loss: 0.068575083 |\n",
      "| Epoch: 10200 | Accuracy: 0.97088 | Loss: 0.068728105 |\n",
      "| Epoch: 10300 | Accuracy: 0.97043 | Loss: 0.068724709 |\n",
      "| Epoch: 10400 | Accuracy: 0.97043 | Loss: 0.068756696 |\n",
      "| Epoch: 10500 | Accuracy: 0.96997 | Loss: 0.068746806 |\n",
      "| Epoch: 10600 | Accuracy: 0.97043 | Loss: 0.068979789 |\n",
      "| Epoch: 10700 | Accuracy: 0.97043 | Loss: 0.068954027 |\n",
      "| Epoch: 10800 | Accuracy: 0.96906 | Loss: 0.068820507 |\n",
      "| Epoch: 10900 | Accuracy: 0.97043 | Loss: 0.068814462 |\n",
      "| Epoch: 11000 | Accuracy: 0.97043 | Loss: 0.068878786 |\n",
      "| Epoch: 11100 | Accuracy: 0.97043 | Loss: 0.068906228 |\n",
      "| Epoch: 11200 | Accuracy: 0.96997 | Loss: 0.068871368 |\n",
      "| Epoch: 11300 | Accuracy: 0.96997 | Loss: 0.068911281 |\n",
      "| Epoch: 11400 | Accuracy: 0.96997 | Loss: 0.069000706 |\n",
      "| Epoch: 11500 | Accuracy: 0.96997 | Loss: 0.068930412 |\n",
      "| Epoch: 11600 | Accuracy: 0.96997 | Loss: 0.068988059 |\n",
      "| Epoch: 11700 | Accuracy: 0.96997 | Loss: 0.068913504 |\n",
      "| Epoch: 11800 | Accuracy: 0.96997 | Loss: 0.068867309 |\n",
      "| Epoch: 11900 | Accuracy: 0.96997 | Loss: 0.068855245 |\n",
      "| Epoch: 12000 | Accuracy: 0.96997 | Loss: 0.068746454 |\n",
      "| Epoch: 12100 | Accuracy: 0.96997 | Loss: 0.068704117 |\n",
      "| Epoch: 12200 | Accuracy: 0.97043 | Loss: 0.068666994 |\n",
      "| Epoch: 12300 | Accuracy: 0.97043 | Loss: 0.068549459 |\n",
      "| Epoch: 12400 | Accuracy: 0.97043 | Loss: 0.068535903 |\n",
      "| Epoch: 12500 | Accuracy: 0.97043 | Loss: 0.068300301 |\n",
      "| Epoch: 12600 | Accuracy: 0.97043 | Loss: 0.068330753 |\n",
      "| Epoch: 12700 | Accuracy: 0.96997 | Loss: 0.068303263 |\n",
      "| Epoch: 12800 | Accuracy: 0.97043 | Loss: 0.068326917 |\n",
      "| Epoch: 12900 | Accuracy: 0.97043 | Loss: 0.068114719 |\n",
      "| Epoch: 13000 | Accuracy: 0.96997 | Loss: 0.068005631 |\n",
      "| Epoch: 13100 | Accuracy: 0.97043 | Loss: 0.067894469 |\n",
      "| Epoch: 13200 | Accuracy: 0.97088 | Loss: 0.067845255 |\n",
      "| Epoch: 13300 | Accuracy: 0.97088 | Loss: 0.067880918 |\n",
      "| Epoch: 13400 | Accuracy: 0.97088 | Loss: 0.067976515 |\n",
      "| Epoch: 13500 | Accuracy: 0.97134 | Loss: 0.067795376 |\n",
      "| Epoch: 13600 | Accuracy: 0.97088 | Loss: 0.067740371 |\n",
      "| Epoch: 13700 | Accuracy: 0.97134 | Loss: 0.067822302 |\n",
      "| Epoch: 13800 | Accuracy: 0.97134 | Loss: 0.067711133 |\n",
      "| Epoch: 13900 | Accuracy: 0.97134 | Loss: 0.067666771 |\n",
      "| Epoch: 14000 | Accuracy: 0.97134 | Loss: 0.067620678 |\n",
      "| Epoch: 14100 | Accuracy: 0.97088 | Loss: 0.067707926 |\n",
      "| Epoch: 14200 | Accuracy: 0.97043 | Loss: 0.067589835 |\n",
      "| Epoch: 14300 | Accuracy: 0.97134 | Loss: 0.067595759 |\n",
      "| Epoch: 14400 | Accuracy: 0.97179 | Loss: 0.067470627 |\n",
      "| Epoch: 14500 | Accuracy: 0.97088 | Loss: 0.067638753 |\n",
      "| Epoch: 14600 | Accuracy: 0.97088 | Loss: 0.067538760 |\n",
      "| Epoch: 14700 | Accuracy: 0.97179 | Loss: 0.067588821 |\n",
      "| Epoch: 14800 | Accuracy: 0.97088 | Loss: 0.067603264 |\n",
      "| Epoch: 14900 | Accuracy: 0.97134 | Loss: 0.067591783 |\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "train_loss_PNN, test_loss_PNN, parameter_PNN = training.train_normal_pnn(\n",
    "    PNN, train_loader, test_loader, m, T, optimizer_PNN, pnn.LossFunction, 15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "811173a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6783, tensor(0.0670, dtype=torch.float64))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_PNN, '-', label='train')\n",
    "plt.plot(test_loss_PNN, '--', label='test')\n",
    "plt.legend()\n",
    "best = np.argmin(test_loss_PNN)\n",
    "PNN.load_state_dict(parameter_PNN)\n",
    "best, test_loss_PNN[best]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd94766",
   "metadata": {},
   "source": [
    "## save PNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab12e33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./pendigitresult/PNN_16.p', 'wb') as f:\n",
    "    pickle.dump(PNN, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0196479",
   "metadata": {},
   "source": [
    "## load PNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53d4cca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./pendigitresult/PNN_16.p', 'rb') as f:\n",
    "    PNN = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17febee",
   "metadata": {},
   "source": [
    "## Functions for setting times and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b93c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PNN_Setting as ps\n",
    "# ps.makemodel\n",
    "# ps.settime\n",
    "# ps.zerogradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cf0a93",
   "metadata": {},
   "source": [
    "Usage of functions: \n",
    "\n",
    "`pnn.apply(lambda z: settime(z, time))`\n",
    "\n",
    "`pnn.apply(makemodel)`\n",
    "\n",
    "`pnn.apply(zerogradient)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a1d3d4",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5e2086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluation\n",
    "importlib.reload(evaluation)\n",
    "mean_acc_PNN, std_acc_PNN, mean_maa_PNN, std_maa_PNN = evaluation.FullEvaluation(PNN, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d9508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fill_between(np.linspace(0,1,50), mean_acc_PNN-std_acc_PNN, mean_acc_PNN+std_acc_PNN, alpha=0.3, color='blue');\n",
    "plt.plot(np.linspace(0,1,50), mean_acc_PNN, label='PNN', color='blue');\n",
    "\n",
    "plt.xlabel('normalized time');\n",
    "plt.ylabel('basic accuracy');\n",
    "plt.xlim([0, 1]);\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45766c5f-ca2e-4bff-9e13-25f1e8406fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fill_between(np.linspace(0,1,50), mean_maa_PNN-std_maa_PNN, mean_maa_PNN+std_maa_PNN, alpha=0.3, color='blue');\n",
    "plt.plot(np.linspace(0,1,50), mean_maa_PNN, label='PNN', color='blue');\n",
    "\n",
    "plt.xlabel('normalized time');\n",
    "plt.ylabel('measureing aware accuracy');\n",
    "plt.xlim([0, 1]);\n",
    "plt.ylim([0, 1]);\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff7c1f0",
   "metadata": {},
   "source": [
    "# Aging Aware PNN\n",
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b474bd81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): PNNLayer()\n",
       "  (1): PNNLayer()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AAPNN = torch.nn.Sequential(pnn.PNNLayer(N_features, N_Hidden, age_generator),\n",
    "                            pnn.PNNLayer(N_Hidden, N_class, age_generator))\n",
    "\n",
    "optimizer_AAPNN = torch.optim.Adam(AAPNN.parameters(), lr=0.01)\n",
    "AAPNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5e8432",
   "metadata": {},
   "source": [
    "### Functions for generating parallel AAPNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "159ff692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps.MakeParallelPNNs\n",
    "# ps.MakeParallelModels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b40f37b",
   "metadata": {},
   "source": [
    "Usage:\n",
    "\n",
    "`Parallel_PNNs = ps.MakeParallelPNNs(pnn, M, K)`, generating different models & different time stamps\n",
    "\n",
    "`Parallel_PNNs = ps.MakeParallelPNNs(pnn, M)`, generating only different models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5b1f11-88d5-4057-a090-a2748af6bdb3",
   "metadata": {},
   "source": [
    "# Load temp parameter when corrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93161d57-aef1-4417-812c-539600f09f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./temp/AAPNN.p', 'rb') as f:\n",
    "    AAPNN = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0df146-6c60-415d-8769-29c3474578e0",
   "metadata": {},
   "source": [
    "## Parallel Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5b541a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0702789c7bc7430cb4f2f1a33f09c909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch:     0 | Accuracy: 0.94731 | Loss: 0.119449699 |\n",
      "| Epoch:    10 | Accuracy: 0.94712 | Loss: 0.118456288 |\n",
      "| Epoch:    20 | Accuracy: 0.94414 | Loss: 0.122467509 |\n",
      "| Epoch:    30 | Accuracy: 0.94460 | Loss: 0.123668528 |\n",
      "| Epoch:    40 | Accuracy: 0.94835 | Loss: 0.120239478 |\n",
      "| Epoch:    50 | Accuracy: 0.94629 | Loss: 0.120257280 |\n",
      "| Epoch:    60 | Accuracy: 0.94148 | Loss: 0.129778863 |\n",
      "| Epoch:    70 | Accuracy: 0.94413 | Loss: 0.124345367 |\n",
      "| Epoch:    80 | Accuracy: 0.94520 | Loss: 0.119336491 |\n",
      "| Epoch:    90 | Accuracy: 0.94426 | Loss: 0.124273807 |\n",
      "| Epoch:   100 | Accuracy: 0.94723 | Loss: 0.116826617 |\n",
      "| Epoch:   110 | Accuracy: 0.94564 | Loss: 0.125007846 |\n",
      "| Epoch:   120 | Accuracy: 0.94247 | Loss: 0.127981235 |\n",
      "| Epoch:   130 | Accuracy: 0.94385 | Loss: 0.124011203 |\n",
      "| Epoch:   140 | Accuracy: 0.94864 | Loss: 0.115404072 |\n",
      "| Epoch:   150 | Accuracy: 0.94321 | Loss: 0.126193432 |\n",
      "| Epoch:   160 | Accuracy: 0.94813 | Loss: 0.116995077 |\n",
      "| Epoch:   170 | Accuracy: 0.94290 | Loss: 0.124834786 |\n",
      "| Epoch:   180 | Accuracy: 0.94548 | Loss: 0.121918932 |\n",
      "| Epoch:   190 | Accuracy: 0.94567 | Loss: 0.122529363 |\n",
      "| Epoch:   200 | Accuracy: 0.94366 | Loss: 0.125771152 |\n",
      "| Epoch:   210 | Accuracy: 0.94124 | Loss: 0.130905923 |\n",
      "| Epoch:   220 | Accuracy: 0.94508 | Loss: 0.121530213 |\n",
      "| Epoch:   230 | Accuracy: 0.94436 | Loss: 0.125182464 |\n",
      "| Epoch:   240 | Accuracy: 0.94216 | Loss: 0.125754452 |\n",
      "| Epoch:   250 | Accuracy: 0.94063 | Loss: 0.127815565 |\n",
      "| Epoch:   260 | Accuracy: 0.94468 | Loss: 0.125246886 |\n",
      "| Epoch:   270 | Accuracy: 0.94637 | Loss: 0.122195179 |\n",
      "| Epoch:   280 | Accuracy: 0.94510 | Loss: 0.121936321 |\n",
      "| Epoch:   290 | Accuracy: 0.94832 | Loss: 0.117690629 |\n",
      "| Epoch:   300 | Accuracy: 0.94278 | Loss: 0.130842278 |\n",
      "| Epoch:   310 | Accuracy: 0.94658 | Loss: 0.118407142 |\n",
      "| Epoch:   320 | Accuracy: 0.94617 | Loss: 0.119965557 |\n",
      "| Epoch:   330 | Accuracy: 0.94661 | Loss: 0.122635292 |\n",
      "| Epoch:   340 | Accuracy: 0.94126 | Loss: 0.131640769 |\n",
      "| Epoch:   350 | Accuracy: 0.94497 | Loss: 0.123811084 |\n",
      "| Epoch:   360 | Accuracy: 0.94357 | Loss: 0.123797481 |\n",
      "| Epoch:   370 | Accuracy: 0.94285 | Loss: 0.127234520 |\n",
      "| Epoch:   380 | Accuracy: 0.94010 | Loss: 0.130594269 |\n",
      "| Epoch:   390 | Accuracy: 0.94198 | Loss: 0.129199070 |\n",
      "| Epoch:   400 | Accuracy: 0.94331 | Loss: 0.128155885 |\n",
      "| Epoch:   410 | Accuracy: 0.94347 | Loss: 0.124584174 |\n",
      "| Epoch:   420 | Accuracy: 0.94753 | Loss: 0.121681590 |\n",
      "| Epoch:   430 | Accuracy: 0.94527 | Loss: 0.123020492 |\n",
      "| Epoch:   440 | Accuracy: 0.94523 | Loss: 0.122455986 |\n",
      "| Epoch:   450 | Accuracy: 0.94198 | Loss: 0.127088843 |\n",
      "| Epoch:   460 | Accuracy: 0.94378 | Loss: 0.125922480 |\n",
      "| Epoch:   470 | Accuracy: 0.94317 | Loss: 0.125040733 |\n",
      "| Epoch:   480 | Accuracy: 0.94532 | Loss: 0.124832017 |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/scratch/slurm_tmpdir/job_20257366/ipykernel_1226855/3468963419.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m test_loss_AAPNN, parameter_AAPNN = training.ParallelTrainingAAPNN(AAPNN,\n\u001b[0m\u001b[1;32m      3\u001b[0m                                                                   \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                                   \u001b[0moptimizer_AAPNN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                                   \u001b[0mpnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLossFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/pfs/data5/home/kit/tm/px3192/Aging-aware-training/training.py\u001b[0m in \u001b[0;36mParallelTrainingAAPNN\u001b[0;34m(AAPNN, train_loader, test_loader, optimizer, lossfunction, m, T, M, K, M_test, K_test, Epoch)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEpoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0mParallel_Models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMakeParallelModels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAAPNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         gradients = Parallel(n_jobs=M)(delayed(GetGradientFor)(aapnn,\n",
      "\u001b[0;32m/pfs/data5/home/kit/tm/px3192/Aging-aware-training/PNN_Setting.py\u001b[0m in \u001b[0;36mMakeParallelModels\u001b[0;34m(pnn, M)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# change aging model for each pnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpnn_with_different_models\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmakemodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpnn_with_different_models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    657\u001b[0m         \"\"\"\n\u001b[1;32m    658\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/pfs/data5/home/kit/tm/px3192/Aging-aware-training/PNN_Setting.py\u001b[0m in \u001b[0;36mmakemodel\u001b[0;34m(m)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmakemodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPNNLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_aging_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mzerogradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/pfs/data5/home/kit/tm/px3192/Aging-aware-training/pNN_aging_aware.py\u001b[0m in \u001b[0;36mgenerate_aging_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_aging_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maging_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotalnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/pfs/data5/home/kit/tm/px3192/Aging-aware-training/Aging_Model/aging_model_generator.py\u001b[0m in \u001b[0;36mget_models\u001b[0;34m(self, number_of_models)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mExp_aging_model_sampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAging_model_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_models\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mExponentialFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/pfs/data5/home/kit/tm/px3192/Aging-aware-training/Aging_Model/aging_model_generator.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mExp_aging_model_sampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAging_model_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_models\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mExponentialFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/pfs/data5/home/kit/tm/px3192/Aging-aware-training/Aging_Model/aging_model_generator.py\u001b[0m in \u001b[0;36m_get_param_sample\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_param_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;34m''' samples from the param distributions '''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/pfs/data5/home/kit/tm/px3192/Aging-aware-training/Aging_Model/aging_model_generator.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_param_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;34m''' samples from the param distributions '''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/bwhpc/common/jupyter/base/2021-09-30/lib/python3.8/site-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36mrvs\u001b[0;34m(self, size, random_state)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'random_state'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/bwhpc/common/jupyter/base/2021-09-30/lib/python3.8/site-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36mrvs\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m   1073\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrndm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mrandom_state_saved\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m             \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrndm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1076\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m             \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/bwhpc/common/jupyter/base/2021-09-30/lib/python3.8/site-packages/scipy/_lib/_util.py\u001b[0m in \u001b[0;36mcheck_random_state\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmtrand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_mt19937.pyx\u001b[0m in \u001b[0;36mnumpy.random._mt19937.MT19937.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MachineLearning/lib/python3.8/contextlib.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "importlib.reload(training)\n",
    "test_loss_AAPNN, parameter_AAPNN = training.ParallelTrainingAAPNN(AAPNN,\n",
    "                                                                  train_loader, test_loader,\n",
    "                                                                  optimizer_AAPNN,\n",
    "                                                                  pnn.LossFunction, m, T,\n",
    "                                                                  M, K, M_test, K_test, Epoch=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da97f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_loss_AAPNN);\n",
    "AAPNN.load_state_dict(parameter_AAPNN);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88aae576-7040-4c99-8aab-c2d611acb10c",
   "metadata": {},
   "source": [
    "## save AAPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9678c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./pendigitresult/AAPNN_16.p', 'wb') as f:\n",
    "    pickle.dump(AAPNN, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406d739d",
   "metadata": {},
   "source": [
    "## read AAPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1dbe07b-0c37-4eaf-8342-b2d16b2f2c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./pendigitresult/AAPNN_16.p', 'rb') as f:\n",
    "    AAPNN = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8058c682",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fdc2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluation\n",
    "mean_acc_AAPNN, std_acc_AAPNN, mean_maa_AAPNN, std_maa_AAPNN = evaluation.FullEvaluation(AAPNN, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a6579d-bf1e-4e0a-b409-1aa3ca378945",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fill_between(np.linspace(0,1,50), mean_acc_AAPNN-std_acc_AAPNN, mean_acc_AAPNN+std_acc_AAPNN, alpha=0.3, color='red');\n",
    "plt.plot(np.linspace(0,1,50), mean_acc_AAPNN, label='AAPNN', color='red');\n",
    "\n",
    "plt.xlabel('normalized time');\n",
    "plt.ylabel('basic accuracy');\n",
    "plt.xlim([0, 1]);\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabae09a-3b1b-4d63-871d-b8a8e7dfb920",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fill_between(np.linspace(0,1,50), mean_maa_AAPNN-std_maa_AAPNN, mean_maa_AAPNN+std_maa_AAPNN, alpha=0.3, color='red');\n",
    "plt.plot(np.linspace(0,1,50), mean_maa_AAPNN, label='AAPNN', color='red');\n",
    "\n",
    "plt.xlabel('normalized time');\n",
    "plt.ylabel('measureing aware accuracy');\n",
    "plt.xlim([0, 1]);\n",
    "plt.ylim([0, 1]);\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b89103-68b9-4907-919e-8cd836c13245",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "machinelearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
