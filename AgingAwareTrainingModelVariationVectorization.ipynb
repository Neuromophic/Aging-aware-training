{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0f1319a",
   "metadata": {},
   "source": [
    "# Aging Aware with Model Variation\n",
    "Previously, we optimize the following functional:\n",
    "$$ \\min_\\theta \\, \\int_{t=0}^{1} \\; L(\\theta(t)) \\, {\\rm d}t. $$\n",
    "The optimum is for a specific aging model $\\omega$, i.e., we minimized the \n",
    "$$ \\min_\\theta \\, \\int_{t=0}^{1} \\; L(\\theta(t,\\omega)) \\, {\\rm d}t. $$\n",
    "However, we dont know how will the resistance decay, i.e., we should also minimize the loss function w.r.t. aging models with different parameters. That means we need to optimized\n",
    "$$ \\min_\\theta \\, \\int_{\\omega}\\int_{t=0}^{1} \\; L(\\theta(t,\\omega)) \\, {\\rm d}t\\, p(\\omega){\\rm d}\\omega. $$\n",
    "The Mento Carlo Approximation is then\n",
    "$$\n",
    "\\min_{\\theta_{\\rm init}} \\frac{1}{\\Omega}\\frac{1}{K}\\sum_{\\omega\\in\\mathfrak{M}}\\sum_{k\\in \\mathfrak{K} } L \\left(\\theta[k, \\omega]\\right),\n",
    "$$\n",
    "where $\\mathfrak{M}$ is the set of $\\Omega$ elements following the distribution $p(\\omega)$. $p(\\omega)$ is the distributions of parameters of the aging model. We have already obtained these distributions as we modeled the aging decay.\n",
    "\n",
    "That means we should optimize this problem by\n",
    "$$\n",
    "\\begin{align}\n",
    "\\theta_{\\rm init}&:=\\theta_{\\rm init} - \\alpha\\cdot\\nabla_{\\theta_{\\rm init}}\\left(\\frac{1}{\\Omega}\\frac{1}{K}\\sum_{\\omega\\in\\mathfrak{M}}\\sum_{k\\in \\mathfrak{K} } L \\left(\\theta[k, \\omega]\\right)\\right)\\\\\n",
    "&=\\theta_{\\rm init} - \\frac{\\alpha}{\\Omega K}\\cdot\\nabla_{\\theta_{\\rm init}}\\left(\\sum_{\\omega\\in\\mathfrak{M}}\\sum_{k\\in \\mathfrak{K} } L \\left(\\theta[k, \\omega]\\right)\\right)\\\\\n",
    "&=\\theta_{\\rm init} - \\frac{\\alpha}{\\Omega K}\\left(\\sum_{\\omega\\in\\mathfrak{M}}\\sum_{k\\in \\mathfrak{K} }\\nabla_{\\theta_{\\rm init}} L \\left(\\theta[k, \\omega]\\right)\\right)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab183f8",
   "metadata": {},
   "source": [
    "# Get aging model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bc40b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "sys.path.append(os.path.join(os.getcwd(), 'Aging_Model'))\n",
    "\n",
    "with open(os.path.join(os.getcwd(), 'Aging_Model', 'exp_aging_model.p'), 'rb') as f:\n",
    "    age_generator = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15519567",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9b925b",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd3f8c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10992, 16]), torch.Size([10992]), 10992, 16, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath = os.path.join(os.getcwd(), 'Datasets', 'PMLC',\n",
    "                        'data_processed', 'Dataset_Pendigits.p')\n",
    "with open(datapath, 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "X = dataset['X'].float()\n",
    "y = dataset['y']\n",
    "M, N_features, N_class = X.shape[0], X.shape[1], torch.max(\n",
    "    torch.unique(y)).item()+1\n",
    "X.shape, y.shape, M, N_features, N_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35adbc19",
   "metadata": {},
   "source": [
    "## data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea0969cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(1.))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalization\n",
    "X = X / (torch.max(X, axis=0)[0] - torch.min(X, axis=0)[0])\n",
    "X = X - torch.min(X, axis=0)[0]\n",
    "torch.min(X), torch.max(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d04d54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4700, 1.0000, 0.2700, 0.8100, 0.5700, 0.3700, 0.2600, 0.0000, 0.0000],\n",
       "        [0.0000, 0.8900, 0.2700, 1.0000, 0.4200, 0.7500, 0.2900, 0.4500, 0.1500],\n",
       "        [0.0000, 0.5700, 0.3100, 0.6800, 0.7200, 0.9000, 1.0000, 1.0000, 0.7600],\n",
       "        [0.0000, 1.0000, 0.0700, 0.9200, 0.0500, 0.6800, 0.1900, 0.4500, 0.8600],\n",
       "        [0.0000, 0.6700, 0.4900, 0.8300, 1.0000, 1.0000, 0.8100, 0.8000, 0.6000],\n",
       "        [1.0000, 1.0000, 0.8800, 0.9900, 0.4900, 0.7400, 0.1700, 0.4700, 0.0000],\n",
       "        [0.0000, 1.0000, 0.0300, 0.7200, 0.2600, 0.3500, 0.8500, 0.3500, 1.0000],\n",
       "        [0.0000, 0.3900, 0.0200, 0.6200, 0.1100, 0.0500, 0.6300, 0.0000, 1.0000],\n",
       "        [0.1300, 0.8900, 0.1200, 0.5000, 0.7200, 0.3800, 0.5600, 0.0000, 0.0400],\n",
       "        [0.5700, 1.0000, 0.2200, 0.7200, 0.0000, 0.3100, 0.2500, 0.0000, 0.7500]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10, :9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d30ecfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6595, 2198, 2199)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# generate tensordataset\n",
    "dataset = TensorDataset(X, y)\n",
    "\n",
    "# split\n",
    "train_rate = 0.6\n",
    "test_rate = 0.2\n",
    "M_train = int(M*train_rate)\n",
    "M_test = int(M*test_rate)\n",
    "train_data, rest_data = random_split(dataset, [M_train, M-M_train], generator=torch.Generator().manual_seed(19950102))\n",
    "test_data, valid_data = random_split(rest_data, [M_test, M-M_train-M_test], generator=torch.Generator().manual_seed(19950102))\n",
    "len(train_data), len(test_data), len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f8988b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch\n",
    "train_loader = DataLoader(train_data, batch_size=len(train_data))\n",
    "test_loader = DataLoader(test_data, batch_size=len(test_data))\n",
    "valid_loader = DataLoader(valid_data, batch_size=len(valid_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0f57e2",
   "metadata": {},
   "source": [
    "# Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "608550a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Hidden = 16\n",
    "m = 0.3\n",
    "T = 0.1\n",
    "K = 5  # number of time sampling\n",
    "M = 10  # number of model sampling\n",
    "K_test = 5\n",
    "M_test = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff7c1f0",
   "metadata": {},
   "source": [
    "# Aging Aware PNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b474bd81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): PNNLayer()\n",
       "  (1): PNNLayer()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pNN_aging_aware_vectorization as pnnv\n",
    "\n",
    "AAPNN = torch.nn.Sequential(pnnv.PNNLayer(N_features, N_Hidden, age_generator),\n",
    "                            pnnv.PNNLayer(N_Hidden, N_class, age_generator))\n",
    "\n",
    "optimizer_AAPNN = torch.optim.Adam(AAPNN.parameters(), lr=0.01)\n",
    "AAPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dd6fe58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): PNNLayer()\n",
       "  (1): PNNLayer()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AAPNN.apply(lambda z: pnnv.MakeModel(z, M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8796aaa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5, 10992, 16])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xv = X.repeat(M,K,1,1)\n",
    "Xv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a51bf420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5, 10992, 10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = AAPNN(Xv)\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e30017fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pnnv)\n",
    "l = pnnv.LossFunction(prediction, y, 0.3, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c55c3814",
   "metadata": {},
   "outputs": [],
   "source": [
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01e7bf2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.9246e-05,  2.9282e-04, -1.5269e-05,  2.5732e-04,  8.3477e-05,\n",
       "          8.9210e-05,  1.1465e-04, -4.2086e-05,  1.0696e-04, -2.6019e-05,\n",
       "          2.2283e-05,  1.1463e-04,  1.1987e-04,  1.7370e-04,  2.9913e-04,\n",
       "          1.3855e-04,  3.4895e-04, -9.1313e-05],\n",
       "        [-1.0326e-05,  9.5576e-06, -2.9984e-06,  1.3275e-05,  1.4765e-05,\n",
       "          4.0644e-06,  2.8112e-06, -2.3273e-06, -4.6894e-06, -7.3365e-06,\n",
       "         -1.0289e-05, -5.4724e-06, -2.0454e-06, -3.1609e-06,  1.8205e-05,\n",
       "         -1.1077e-06,  1.4632e-05, -1.0832e-05],\n",
       "        [ 7.2025e-04,  2.2064e-03,  6.0857e-04,  2.0832e-03,  7.6821e-04,\n",
       "          1.4851e-03,  6.6165e-04,  5.3485e-04,  8.8463e-04,  1.4643e-04,\n",
       "          1.2872e-03,  1.0438e-04,  1.0830e-03,  0.0000e+00,  4.7367e-04,\n",
       "         -3.9300e-05,  2.3965e-03, -9.5338e-04],\n",
       "        [-2.8188e-04,  2.8729e-04,  3.9899e-05,  3.8659e-04,  3.7205e-04,\n",
       "          4.3388e-04,  4.3354e-04,  2.7659e-04,  2.1281e-04,  1.7176e-04,\n",
       "         -5.2479e-05,  1.0550e-04,  6.6651e-05,  1.4002e-05,  4.9580e-04,\n",
       "         -2.6364e-05,  4.9599e-04, -1.5556e-04],\n",
       "        [ 2.2922e-04,  4.1282e-04, -5.2478e-05,  8.8298e-05, -1.7021e-04,\n",
       "          3.3958e-05, -3.3970e-05, -4.5697e-05,  2.0585e-04,  2.4866e-05,\n",
       "          3.4955e-04,  2.2478e-04,  2.1552e-04,  2.3481e-04,  8.1728e-05,\n",
       "          1.1444e-04,  4.3649e-04, -1.1768e-04],\n",
       "        [ 3.1296e-04,  1.2123e-03,  3.6041e-04,  1.1100e-03,  4.2134e-04,\n",
       "          6.9639e-04,  3.6413e-04,  2.0203e-04,  3.9542e-04,  1.2625e-05,\n",
       "          4.9054e-04,  1.6395e-04,  5.3946e-04,  2.9245e-04,  4.8988e-04,\n",
       "          3.2085e-04,  1.4336e-03, -3.7759e-04],\n",
       "        [ 1.7352e-04,  2.1764e-04, -1.1226e-05,  1.6844e-04, -2.0040e-04,\n",
       "          3.9293e-06, -3.5754e-05,  4.4217e-05,  2.2645e-04,  8.8485e-05,\n",
       "          3.5635e-04,  1.1127e-04,  1.2245e-04, -2.1972e-06, -7.2997e-05,\n",
       "         -1.2106e-04,  1.7749e-04, -4.2825e-05],\n",
       "        [ 7.7064e-06,  9.0229e-04,  1.3916e-04,  9.8781e-04,  2.7729e-04,\n",
       "          6.8832e-04,  2.9065e-04,  2.2611e-04,  3.9549e-04, -3.1392e-05,\n",
       "          5.1521e-04, -2.0072e-04,  3.4709e-04, -2.6649e-04,  9.6852e-05,\n",
       "         -3.1639e-04,  1.0893e-03, -5.6208e-04],\n",
       "        [-2.3109e-04, -3.6517e-04, -1.9749e-04, -3.0803e-04, -1.5651e-04,\n",
       "         -3.0592e-04,  2.8873e-05, -1.2424e-04,  3.0628e-05,  1.1717e-04,\n",
       "         -6.3626e-05,  1.3699e-04, -1.0751e-04,  1.3630e-04, -2.2087e-04,\n",
       "          2.1104e-04, -4.1503e-04,  1.1587e-04],\n",
       "        [ 1.8363e-04,  4.7948e-04,  1.3579e-04,  4.5567e-04,  1.7384e-04,\n",
       "          3.5501e-04,  1.9405e-04,  2.2342e-04,  3.8923e-04,  1.9000e-04,\n",
       "          4.2196e-04,  1.4847e-04,  2.6634e-04,  1.0476e-04,  4.0412e-05,\n",
       "          7.1779e-06,  5.4553e-04, -1.5156e-04],\n",
       "        [ 9.4643e-05,  1.1131e-04, -7.9812e-05,  4.1877e-06, -1.7916e-04,\n",
       "         -1.2176e-04, -3.1077e-05, -9.2941e-05,  8.8493e-05,  3.8398e-05,\n",
       "          1.2375e-04,  1.7399e-04,  8.3646e-05,  1.8215e-04,  1.6790e-05,\n",
       "          1.3549e-04,  3.8336e-05, -1.1818e-05],\n",
       "        [-6.6681e-05, -3.2815e-04, -2.0382e-04, -4.5971e-04, -3.9663e-04,\n",
       "         -3.9894e-04, -2.8113e-04, -2.7227e-04, -9.7493e-05, -1.1804e-04,\n",
       "         -3.3804e-05,  3.1806e-05, -1.9882e-04,  7.5349e-05, -3.7665e-04,\n",
       "          3.8507e-05, -4.0629e-04,  1.1387e-04],\n",
       "        [ 2.1615e-04,  3.8682e-04,  1.3951e-04,  3.3135e-04,  6.2110e-05,\n",
       "          3.0079e-04, -2.9854e-05,  1.0182e-04, -7.9303e-05, -1.4421e-04,\n",
       "          8.0681e-05, -1.1756e-04,  1.3549e-04, -3.6576e-05,  2.7724e-04,\n",
       "         -7.0673e-05,  5.0441e-04, -1.6640e-04],\n",
       "        [ 4.0279e-04,  1.9112e-03,  6.1613e-04,  2.0893e-03,  1.3014e-03,\n",
       "          1.6653e-03,  9.4929e-04,  7.9226e-04,  9.1520e-04,  3.0190e-04,\n",
       "          9.2386e-04,  0.0000e+00,  1.0597e-03,  2.9532e-04,  1.0167e-03,\n",
       "          1.6035e-04,  2.7821e-03, -8.8944e-04],\n",
       "        [ 1.7302e-04,  2.9379e-04,  3.1216e-05,  1.6151e-04, -4.1842e-05,\n",
       "         -5.6285e-06,  5.1933e-07, -5.5896e-05,  2.0505e-04, -4.7424e-06,\n",
       "          3.5097e-04,  1.2575e-04,  1.3244e-04,  2.2427e-04, -2.2408e-04,\n",
       "          0.0000e+00,  2.9645e-04, -8.0944e-05],\n",
       "        [-1.5440e-05,  1.0312e-03,  1.9803e-04,  1.1336e-03,  5.4428e-04,\n",
       "          6.2142e-04,  5.5888e-04,  4.3583e-04,  3.0169e-04,  1.2408e-04,\n",
       "          1.4517e-04,  1.8534e-04,  4.8214e-04,  2.5754e-04,  8.9006e-04,\n",
       "          1.8710e-04,  1.3988e-03, -4.3668e-04]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AAPNN[0].theta_.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff47b8de",
   "metadata": {},
   "source": [
    "# Normal PNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5546a81d",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5fbdddb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): PNNLayer()\n",
       "  (1): PNNLayer()\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pNN_aging_aware_vectorization as pnnv\n",
    "importlib.reload(pnnv)\n",
    "\n",
    "PNN = torch.nn.Sequential(pnnv.PNNLayer(N_features, N_Hidden, age_generator),\n",
    "                            pnnv.PNNLayer(N_Hidden, N_class, age_generator))\n",
    "\n",
    "PNN.apply(pnnv.LockTime)\n",
    "PNN.apply(pnnv.MakeModel)\n",
    "optimizer_PNN = torch.optim.Adam(PNN.parameters(), lr=0.01)\n",
    "PNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5d9f907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  tensor(1.3956)\n",
      "loss:  tensor(1.3936)\n",
      "loss:  tensor(1.3771)\n",
      "loss:  tensor(1.3001)\n",
      "loss:  tensor(0.9969)\n",
      "loss:  tensor(0.7495)\n",
      "loss:  tensor(0.6943)\n",
      "loss:  tensor(0.6715)\n",
      "loss:  tensor(0.6453)\n",
      "loss:  tensor(0.6098)\n",
      "loss:  tensor(0.5690)\n",
      "loss:  tensor(0.5349)\n",
      "loss:  tensor(0.5056)\n",
      "loss:  tensor(0.4750)\n",
      "loss:  tensor(0.4421)\n",
      "loss:  tensor(0.4081)\n",
      "loss:  tensor(0.3780)\n",
      "loss:  tensor(0.3530)\n",
      "loss:  tensor(0.3330)\n",
      "loss:  tensor(0.3157)\n",
      "loss:  tensor(0.3004)\n",
      "loss:  tensor(0.2868)\n",
      "loss:  tensor(0.2748)\n",
      "loss:  tensor(0.2637)\n",
      "loss:  tensor(0.2531)\n",
      "loss:  tensor(0.2434)\n",
      "loss:  tensor(0.2350)\n",
      "loss:  tensor(0.2277)\n",
      "loss:  tensor(0.2213)\n",
      "loss:  tensor(0.2156)\n",
      "loss:  tensor(0.2105)\n",
      "loss:  tensor(0.2058)\n",
      "loss:  tensor(0.2016)\n",
      "loss:  tensor(0.1979)\n",
      "loss:  tensor(0.1947)\n",
      "loss:  tensor(0.1917)\n",
      "loss:  tensor(0.1889)\n",
      "loss:  tensor(0.1863)\n",
      "loss:  tensor(0.1840)\n",
      "loss:  tensor(0.1816)\n",
      "loss:  tensor(0.1793)\n",
      "loss:  tensor(0.1770)\n",
      "loss:  tensor(0.1747)\n",
      "loss:  tensor(0.1724)\n",
      "loss:  tensor(0.1701)\n",
      "loss:  tensor(0.1678)\n",
      "loss:  tensor(0.1655)\n",
      "loss:  tensor(0.1632)\n",
      "loss:  tensor(0.1609)\n",
      "loss:  tensor(0.1586)\n",
      "loss:  tensor(0.1564)\n",
      "loss:  tensor(0.1542)\n",
      "loss:  tensor(0.1522)\n",
      "loss:  tensor(0.1503)\n",
      "loss:  tensor(0.1485)\n",
      "loss:  tensor(0.1467)\n",
      "loss:  tensor(0.1451)\n",
      "loss:  tensor(0.1435)\n",
      "loss:  tensor(0.1419)\n",
      "loss:  tensor(0.1404)\n",
      "loss:  tensor(0.1389)\n",
      "loss:  tensor(0.1375)\n",
      "loss:  tensor(0.1359)\n",
      "loss:  tensor(0.1344)\n",
      "loss:  tensor(0.1329)\n",
      "loss:  tensor(0.1315)\n",
      "loss:  tensor(0.1302)\n",
      "loss:  tensor(0.1290)\n",
      "loss:  tensor(0.1279)\n",
      "loss:  tensor(0.1269)\n",
      "loss:  tensor(0.1258)\n",
      "loss:  tensor(0.1247)\n",
      "loss:  tensor(0.1237)\n",
      "loss:  tensor(0.1226)\n",
      "loss:  tensor(0.1217)\n",
      "loss:  tensor(0.1207)\n",
      "loss:  tensor(0.1198)\n",
      "loss:  tensor(0.1188)\n",
      "loss:  tensor(0.1179)\n",
      "loss:  tensor(0.1171)\n",
      "loss:  tensor(0.1162)\n",
      "loss:  tensor(0.1153)\n",
      "loss:  tensor(0.1145)\n",
      "loss:  tensor(0.1137)\n",
      "loss:  tensor(0.1129)\n",
      "loss:  tensor(0.1122)\n",
      "loss:  tensor(0.1115)\n",
      "loss:  tensor(0.1107)\n",
      "loss:  tensor(0.1101)\n",
      "loss:  tensor(0.1093)\n",
      "loss:  tensor(0.1086)\n",
      "loss:  tensor(0.1079)\n",
      "loss:  tensor(0.1073)\n",
      "loss:  tensor(0.1066)\n",
      "loss:  tensor(0.1059)\n",
      "loss:  tensor(0.1053)\n",
      "loss:  tensor(0.1047)\n",
      "loss:  tensor(0.1042)\n",
      "loss:  tensor(0.1035)\n",
      "loss:  tensor(0.1029)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    for x_train, y_train in train_loader:\n",
    "        optimizer_PNN.zero_grad()\n",
    "\n",
    "        xv_train = x_train.repeat(1,1,1,1)\n",
    "        prediction = PNN(xv_train)\n",
    "        loss = pnnv.LossFunction(prediction, y_train, m, T)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer_PNN.step()\n",
    "    \n",
    "    for x_test, y_test in test_loader:\n",
    "        xv_test = x_test.repeat(1,1,1,1)\n",
    "        prediction_test = PNN(xv_test)\n",
    "        loss_test = pnnv.LossFunction(prediction_test, y_test, m, T)\n",
    "        \n",
    "        if not epoch % 10:\n",
    "            print('loss: ',loss_test.data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06463c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccd54b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
